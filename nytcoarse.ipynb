{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import re\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.decomposition import PCA\n",
    "from shutil import copyfile\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture._gaussian_mixture import _estimate_gaussian_parameters\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.dataset_name = \"yelp\"\n",
    "args.gpu = 1\n",
    "args.pca = 128\n",
    "args.random_state = 42\n",
    "args.emb_dim = 768\n",
    "args.num_heads = 2\n",
    "args.batch_size = 64\n",
    "args.temp = 0.2\n",
    "args.lr = 1e-3\n",
    "args.epochs = 5\n",
    "args.accum_steps = 1\n",
    "args.max_sent = 150\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name)\n",
    "new_data_path = os.path.join(\"/home/pk36/MEGClass/intermediate_data\", args.dataset_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this is where we save all representations\n",
    "if not os.path.exists(new_data_path):\n",
    "    os.makedirs(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = os.path.join(\"/shared/data2/pk36/multidim/multigran\")\n",
    "INTERMEDIATE_DATA_FOLDER_PATH = os.path.join(\"/home/pk36/MEGClass/intermediate_data\")\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.clone().detach().cpu().numpy()\n",
    "\n",
    "def sentenceToClass(sent_repr, class_repr, weights):\n",
    "    # sent_repr: N x S x E\n",
    "    # class_repr: C x E\n",
    "    # weights: N x S # equals 0 for masked sentences\n",
    "\n",
    "    #cos-sim between (N x S) x E and (C x E) = N x S x C\n",
    "    m, n = sent_repr.shape[:2]\n",
    "    sentcos = cosine_similarity(sent_repr.reshape(m*n,-1), class_repr).reshape(m,n,-1)\n",
    "    sent_to_class = np.argmax(sentcos, axis=2) # N x S\n",
    "    sent_to_doc_class = np.sum(np.multiply(sent_to_class, weights), axis=1) # N x 1\n",
    "    return sent_to_doc_class\n",
    "\n",
    "def docToClass(doc_repr, class_repr):\n",
    "    # doc_repr: N x E\n",
    "    # class_repr: C x E\n",
    "\n",
    "    #cos-sim between N x E and C x E = N x C\n",
    "    doccos = cosine_similarity(doc_repr, class_repr)\n",
    "    doc_to_class = np.argmax(doccos, axis=1) # N x 1\n",
    "    return doc_to_class\n",
    "\n",
    "def evaluate_predictions(true_class, predicted_class, output_to_console=True, return_tuple=False, return_confusion=False):\n",
    "    confusion = confusion_matrix(true_class, predicted_class)\n",
    "    if return_confusion and output_to_console:\n",
    "        print(\"-\" * 80 + \"Evaluating\" + \"-\" * 80)\n",
    "        print(confusion)\n",
    "    \n",
    "    f1_micro = f1_score(true_class, predicted_class, average='micro')\n",
    "    f1_macro = f1_score(true_class, predicted_class, average='macro')\n",
    "    if output_to_console:\n",
    "        print(\"F1 micro: \" + str(f1_micro))\n",
    "        print(\"F1 macro: \" + str(f1_macro))\n",
    "    if return_tuple:\n",
    "        return confusion, f1_macro, f1_micro\n",
    "    else:\n",
    "        return {\n",
    "            \"confusion\": confusion.tolist(),\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro\n",
    "        }\n",
    "    \n",
    "def getSentClassRepr(args):\n",
    "    with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, f\"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "        dictionary = pk.load(f)\n",
    "        class_repr = dictionary[\"class_representations\"]\n",
    "        sent_repr = dictionary[\"sent_representations\"]\n",
    "    return sent_repr, class_repr\n",
    "\n",
    "\n",
    "def getDSMapAndGold(args, sent_dict):\n",
    "    # get the ground truth labels for all documents and assign a \"ground truth\" label to each sentence based on its parent document\n",
    "    gold_labels = list(map(int, open(os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"labels.txt\"), \"r\").read().splitlines()))\n",
    "    gold_sent_labels = []\n",
    "    # get all sent ids for each doc\n",
    "    doc_to_sent = []\n",
    "    sent_id = 0\n",
    "    for doc_id, doc in enumerate(sent_dict.values()):\n",
    "        sent_ids = []\n",
    "        for sent in doc:\n",
    "            sent_ids.append(sent_id)\n",
    "            gold_sent_labels.append(gold_labels[doc_id])\n",
    "            sent_id += 1\n",
    "        doc_to_sent.append(sent_ids)\n",
    "            \n",
    "    return gold_labels, gold_sent_labels, doc_to_sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-Based Sentence Embeddings, Initial Doc Embeddings, & Class Representations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertSentenceEmb(args, doc_to_sent, sent_repr):\n",
    "    num_docs = len(doc_to_sent)\n",
    "    doc_lengths = np.zeros(num_docs, dtype=int)\n",
    "    # init_doc_repr = np.zeros((num_docs, args.emb_dim))\n",
    "    padded_sent_repr = np.zeros((num_docs, args.max_sent, args.emb_dim))\n",
    "    sentence_mask = np.ones((num_docs, args.max_sent))\n",
    "    trimmed = 0\n",
    "\n",
    "\n",
    "    for doc_id in tqdm(np.arange(num_docs)):\n",
    "        start_sent = doc_to_sent[doc_id][0]\n",
    "        end_sent = doc_to_sent[doc_id][-1]\n",
    "        num_sent = end_sent - start_sent + 1\n",
    "        if num_sent > args.max_sent:\n",
    "            end_sent = start_sent + args.max_sent - 1\n",
    "            num_sent = args.max_sent\n",
    "            trimmed += 1\n",
    "        embeddings = sent_repr[start_sent:end_sent+1]\n",
    "\n",
    "        # save the number of sentences in each document\n",
    "        doc_lengths[doc_id] = int(num_sent)\n",
    "\n",
    "        # Add initial doc representation\n",
    "        # init_doc_repr[doc_id, :] = np.mean(embeddings, axis=0)\n",
    "        # Add padded sentences\n",
    "        padded_sent_repr[doc_id, :embeddings.shape[0], :] = embeddings\n",
    "        # Update mask so that padded sentences are not included in attention computation\n",
    "        sentence_mask[doc_id, :num_sent] = 0\n",
    "\n",
    "    \n",
    "    print(f\"Trimmed Documents: {trimmed}\")\n",
    "\n",
    "    return padded_sent_repr, doc_lengths, sentence_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class Weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetClasses(padded_sent_repr, doc_lengths, class_repr, weights=None):\n",
    "    # weights: N x 150\n",
    "    class_weights = np.zeros((padded_sent_repr.shape[0], class_repr.shape[0])) # N x C\n",
    "    sent_weights = np.zeros(padded_sent_repr.shape[:2])\n",
    "\n",
    "    for doc_id in tqdm(np.arange(padded_sent_repr.shape[0])):\n",
    "        l = doc_lengths[doc_id]\n",
    "        sent_emb = padded_sent_repr[doc_id, :l, :] # S x E\n",
    "        sentcos = cosine_similarity(sent_emb, class_repr) # S x C\n",
    "        sent_to_class = np.argmax(sentcos, axis=1) # S\n",
    "        \n",
    "        # default: equal vote weight between all sentences\n",
    "        if weights is None:\n",
    "            # w = np.ones(doc_lengths[doc_id])/doc_lengths[doc_id]\n",
    "            # top cos-sim - second cos-sim\n",
    "            toptwo = np.partition(sentcos, -2)[:, -2:] # S x 2\n",
    "            toptwo = toptwo[:, 1] - toptwo[:, 0] # S\n",
    "            w = toptwo / np.sum(toptwo)\n",
    "            sent_weights[doc_id, :l] = w\n",
    "        else:\n",
    "            w = weights[doc_id, :l]\n",
    "        \n",
    "        class_weights[doc_id, :] = np.bincount(sent_to_class, weights=w, minlength=class_repr.shape[0])\n",
    "\n",
    "    if weights is None:\n",
    "        return class_weights, sent_weights\n",
    "    else:\n",
    "        return class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial embeddings and class representations + gold labels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_repr, class_repr = getSentClassRepr(args)\n",
    "num_classes = class_repr.shape[0]\n",
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"dataset.pk\"), \"rb\") as f:\n",
    "    dataset = pk.load(f)\n",
    "    sent_dict = dataset[\"sent_data\"]\n",
    "    cleaned_text = dataset[\"cleaned_text\"]\n",
    "    class_names = np.array(dataset[\"class_names\"])\n",
    "gold_labels, gold_sent_labels, doc_to_sent = getDSMapAndGold(args, sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38000/38000 [00:00<00:00, 48620.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38000/38000 [00:09<00:00, 4009.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((38000, 150, 768), (38000,), (38000, 150), (38000, 2), (38000, 150))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "padded_sent_repr, doc_lengths, sentence_mask = bertSentenceEmb(args, doc_to_sent, sent_repr)\n",
    "init_class_weights, init_sent_weights = getTargetClasses(padded_sent_repr, doc_lengths, class_repr, None)\n",
    "padded_sent_repr.shape, doc_lengths.shape, sentence_mask.shape, init_class_weights.shape, init_sent_weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Evaluate Class Weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro: 0.7816578947368421\n",
      "F1 macro: 0.7744238318317597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[11449, 7551], [746, 18254]],\n",
       " 'f1_micro': 0.7816578947368421,\n",
       " 'f1_macro': 0.7744238318317597}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(gold_labels, np.argmax(init_class_weights, axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGClassModel(nn.Module):\n",
    "    def __init__(self, D_in, D_hidden, head, dropout=0.0):\n",
    "        super(MEGClassModel, self).__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=D_in, num_heads=head, dropout=dropout, batch_first=True)\n",
    "        self.layernorm = nn.LayerNorm(D_in)\n",
    "        # self.embd = nn.Sequential(\n",
    "        #     nn.Linear(D_in, 2*D_in),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(2*D_in, D_in))\n",
    "        self.embd = nn.Linear(D_in,D_hidden)\n",
    "        self.attention = nn.Linear(D_hidden,1)\n",
    "        \n",
    "    def forward(self, x_org, mask=None):\n",
    "        x, mha_w = self.mha(x_org,x_org,x_org,key_padding_mask=mask)\n",
    "        x = self.layernorm(x_org+x)\n",
    "        \n",
    "        x = self.embd(x)\n",
    "        x = torch.tanh(x) # contextualized sentences\n",
    "        a = self.attention(x)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill_((mask == 1).unsqueeze(-1), float('-inf'))\n",
    "        w = torch.softmax(a, dim=1) # alpha_k\n",
    "        o = torch.matmul(w.permute(0,2,1), x) #doc \n",
    "        return o, mha_w, w, x # contextualized doc, multi-head attention weights, alpha_k, contextualized sent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(sample_outputs, class_indices, class_embds, temp=0.2):\n",
    "    k = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/temp)\n",
    "    loss = -1*(torch.log(k[np.arange(len(class_indices)),class_indices]/k.sum(1))).sum()\n",
    "    return loss/len(sample_outputs)\n",
    "\n",
    "def weighted_contrastive_loss(args, sample_outputs, class_weights, class_embds):\n",
    "    # k: B x C, class_weights: B x C\n",
    "    k = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    weighted_loss = -1 * (torch.log(k/(k.sum(dim=1).unsqueeze(-1))) * class_weights).sum() # B x C -> B\n",
    "    return weighted_loss/len(sample_outputs)\n",
    "\n",
    "def weighted_class_contrastive_loss(sample_outputs, class_weights, class_embds, temp=0.2):\n",
    "    # k: B x C, class_weights: B x C, class_embds: C x E\n",
    "    target = class_weights @ class_embds # B x E\n",
    "    target_cos = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], target).diagonal(offset=0)/temp)\n",
    "    k = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/temp)\n",
    "    loss = -1*(torch.log(target_cos/k.sum(1))).sum()\n",
    "    return loss/len(sample_outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_repr, class_weights, \n",
    "                doc_lengths, new_data_path, device):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask).to(torch.bool)\n",
    "    class_weights = torch.from_numpy(class_weights)\n",
    "    dataset = TensorDataset(sent_representations, mask, class_weights)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 768 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            model.train()\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            input_weights = batch[2].to(device).float()\n",
    "            \n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "\n",
    "            loss = weighted_contrastive_loss(args, c_doc, input_weights, torch.from_numpy(class_repr).float().to(device)) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(dataset_loader)\n",
    "        print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_e{args.epochs}.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    evalsampler = SequentialSampler(dataset)\n",
    "    eval_loader = DataLoader(dataset, sampler=evalsampler, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    doc_predictions = None\n",
    "    attention_weights = np.zeros_like(mask, dtype=float)\n",
    "    updated_sent_repr = np.zeros_like(sent_representations)\n",
    "    final_doc_emb = np.zeros((len(class_weights), args.emb_dim))\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "            c_sent, c_doc, alpha = tensor_to_numpy(c_sent), tensor_to_numpy(c_doc), tensor_to_numpy(torch.squeeze(alpha, dim=2))\n",
    "\n",
    "            final_doc_emb[idx:idx+c_doc.shape[0], :] = c_doc\n",
    "            attention_weights[idx:idx+c_doc.shape[0], :] = alpha\n",
    "            updated_sent_repr[idx:idx+c_doc.shape[0], :, :] = c_sent\n",
    "\n",
    "            idx += c_doc.shape[0]\n",
    "\n",
    "            doc_class = docToClass(c_doc, class_repr)\n",
    "            if doc_predictions is None:\n",
    "                doc_predictions = doc_class\n",
    "            else:\n",
    "                doc_predictions = np.append(doc_predictions, doc_class)\n",
    "    \n",
    "    updated_class_weights = getTargetClasses(updated_sent_repr, doc_lengths, class_repr, attention_weights)\n",
    "\n",
    "    return doc_predictions, final_doc_emb, updated_sent_repr, attention_weights, updated_class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_sent_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secretary_general_kofi_annan said today that iraq has cooperated up to now with united_nations weapons inspectors , so it would be ''premature'' to take military action before inspectors report back on their investigations to the security_council on jan . 27 .\n",
      "of all those expelled , mr . hogan is putting up the biggest fight against the restrictions , asking a federal_judge to overrule the board and mounting a public_relations battle .\n",
      "the school plans to offer scholarships for families who cannot afford tuition , ms . friedman said .\n",
      "''we 've had to deal with very serious issues , '' mr . mccartney said .\n",
      "it also came as china has worked hard to strengthen ties with the bush_administration .\n",
      "''the american administration is trying to create some pretexts to attack iraq , to exercise their aggression against iraq , '' he said .\n",
      "an adviser to mr . edwards said that campaign had deliberately chosen the day after new year 's to go on ''today , '' because the senator 's aides figured , correctly , that not much else would be going on and that the questions in that morning forum would be something less than fierce .\n",
      "''i feel tremendous support for the physicians who have walked out , '' said dr . joe endrich , an internist and the chairman of the board of the weirton medical center .\n",
      "sir edward said he expected consumer_spending and inflation in housing prices to ease without a crash in the booming real_estate market .\n",
      "on long_island , brokers say , the decorating trend is changing , with the formality of contemporary design and its vast white areas highlighted with modernistic steel shapes yielding to the details , colors and informality of the traditional style .\n"
     ]
    }
   ],
   "source": [
    "topsentids = np.argmax(updated_sent_weights, axis=1)\n",
    "for idx in np.arange(10):\n",
    "    print(sent_dict[str(idx)][topsentids[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find really confident sentences\n",
    "def getConfidentSent(weights, sent_emb, class_repr):\n",
    "    topsentids = np.argmax(weights, axis=1)\n",
    "    topembs = np.zeros((sent_emb.shape[0], sent_emb.shape[2]))\n",
    "    for doc_id in np.arange(sent_emb.shape[0]):\n",
    "        topembs[doc_id, :] = sent_emb[doc_id, topsentids[doc_id], :]\n",
    "\n",
    "    topcossim = cosine_similarity(topembs, class_repr) # N x C\n",
    "    toppreds = np.argmax(topcossim, axis=1)\n",
    "    class_sents = [[] for c in range(class_repr.shape[0])]\n",
    "\n",
    "    for id, p in enumerate(toppreds):\n",
    "        # doc id, sent id, sent weight, sent emb\n",
    "        class_sents[p].append((id, topsentids[id], weights[id, topsentids[id]], topembs[id]))\n",
    "    for c in np.arange(len(class_sents)):\n",
    "        total = int(len(class_sents[c])*0.05)\n",
    "        class_sents[c] = sorted(class_sents[c], key=lambda x: x[2], reverse=True)[:total]\n",
    "\n",
    "    return class_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sents = getConfidentSent(init_class_weights, padded_sent_repr, class_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1.0000000000000002 1.0000000000000002\n",
      "the wpp group 's acquisition of the struggling british advertising company cordiant communications group may not be a done deal after all .\n",
      "625\n",
      "1.0000000000000007 1.0000000000000004\n",
      "he told them , aides said , that he wanted to hold a full scale news conference a few hours later .\n",
      "111\n",
      "1.0000000000000002 1.0000000000000002\n",
      "kiplagat , born in kenya , finished third in new york last year .\n",
      "69\n",
      "1.0000000000000002 1.0000000000000002\n",
      "if a scheduled appointment was missed , the health visitor would make a home visit to make sure all was well and to ensure that appointments for checkups and immunizations were kept .\n",
      "75\n",
      "1.0000000000000002 1.0000000000000002\n",
      "more than half of private_school students attend catholic schools , while about a third are enrolled in other religious schools .\n",
      "85\n",
      "1.0000000000000002 1.0000000000000002\n",
      "ft . co op in a loft building elevator , dining_room , den , office , high ceilings , renovated_kitchen , 3 exposures maintenance 1 , 600 , 50 tax deductible , listed at 895 , 000 , 26 weeks on market ( brokers kingman associates stribling wells gay ) tribeca 415 , 000 303 greenwich_street 3 bedroom , 2 1 2 bath , 1 , 300 sq .\n",
      "32\n",
      "0.9997138728619483 0.9993279772161112\n",
      "page_a10 .\n",
      "19\n",
      "0.9947409088024326 0.9926826316690256\n",
      "everything we did just sort of fascinated them . \"\n",
      "60\n",
      "1.0 0.999388076679609\n",
      "'s top weapons inspector , with mr . bush arguing that it demonstrated he was ''right to take action'' in iraq despite its findings that saddam_hussein had eliminated stockpiles of illicit_weapons years before the invasion .\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_sents)):\n",
    "    print(len(class_sents[i]))\n",
    "    top = class_sents[i][1]\n",
    "    print(class_sents[i][0][2], class_sents[i][1][2])\n",
    "    print(sent_dict[str(top[0])][top[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:21<00:00, 27.93it/s]\n",
      " 20%|██        | 1/5 [00:21<01:25, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7060002684593201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:18<00:00, 32.37it/s]\n",
      " 40%|████      | 2/5 [00:39<00:58, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5426245331764221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:17<00:00, 33.21it/s]\n",
      " 60%|██████    | 3/5 [00:57<00:37, 18.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.40575507283210754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:18<00:00, 31.95it/s]\n",
      " 80%|████████  | 4/5 [01:16<00:18, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3907454311847687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:18<00:00, 31.72it/s]\n",
      "100%|██████████| 5/5 [01:34<00:00, 18.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.38512274622917175\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:19<00:00, 30.08it/s]\n",
      "100%|██████████| 38000/38000 [00:08<00:00, 4368.39it/s]\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 5\n",
    "args.lr = 1e-3\n",
    "args.temp = 0.2\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, init_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7907894736842105\n",
      "F1 macro: 0.7853926828426849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[12012, 6988], [962, 18038]],\n",
       " 'f1_micro': 0.7907894736842105,\n",
       " 'f1_macro': 0.7853926828426849}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " array([ True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc_pred == gold_labels)[:10], (gold_labels == np.argmax(init_class_weights, axis=1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 150)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_sent_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights:  [0.47846081 0.52153919]\n",
      "bad ([-0.04573185 -0.1081845 ]) 0.15926334261894226: contrary to other reviews, i have zero complaints about the service or the prices.\n",
      "good ([-0.07114672 -0.03382205]) 0.16140052676200867: i have been getting tire service here for the past 5 years now, and compared to my experience with places like pep boys, these guys are experienced and know what they're doing.\n",
      "bad ([-0.01363032 -0.11388189]) 0.1908542513847351: also, this is one place that i do not feel like i am being taken advantage of, just because of my gender.\n",
      "bad ([ 0.0168174  -0.11937073]) 0.16015806794166565: other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry.\n",
      "bad ([-0.00713463 -0.07132438]) 0.1108829602599144: but here, my service and road coverage has all been well explained - and let up to me to decide.\n",
      "bad ([0.02093715 0.00960349]) 0.09704500436782837: and they just renovated the waiting room.\n",
      "good ([-0.06087189 -0.00820276]) 0.12039586156606674: it looks a lot better than it did in previous years.\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "print(\"Class Weights: \", init_class_weights[doc_id])\n",
    "tok_sents = sent_dict[str(doc_id)]\n",
    "chosen_class = np.argmax(cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr), axis=1)\n",
    "sent_classes = cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr)\n",
    "\n",
    "for s,c,cw,w in zip(tok_sents, class_names[chosen_class.astype(int)], sent_classes, updated_sent_weights[doc_id, :len(tok_sents)]):\n",
    "    print(f'{c} ({cw}) {w}: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.60it/s]\n",
      " 20%|██        | 1/5 [00:17<01:09, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.2325527667999268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 27.78it/s]\n",
      " 40%|████      | 2/5 [00:35<00:53, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7424776554107666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 27.63it/s]\n",
      " 60%|██████    | 3/5 [00:53<00:35, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3872785270214081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.08it/s]\n",
      " 80%|████████  | 4/5 [01:11<00:17, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3500744700431824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 27.44it/s]\n",
      "100%|██████████| 5/5 [01:29<00:00, 17.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3379160463809967\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:19<00:00, 25.61it/s]\n",
      "100%|██████████| 31997/31997 [00:15<00:00, 2073.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.8020439416195269\n",
      "F1 macro: 0.6456836188505892\n"
     ]
    }
   ],
   "source": [
    "# Second Iteration:\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, updated_sent_repr, sentence_mask, class_repr, updated_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "    reprpickle = pk.load(f)\n",
    "    class_words = reprpickle[\"class_words\"]\n",
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"dataset.pk\"), \"rb\") as f:\n",
    "    datapk = pk.load(f)\n",
    "    sent_dict = datapk[\"sent_data\"]\n",
    "    class_names = np.array(datapk[\"class_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arts',\n",
       " 'artists',\n",
       " 'art',\n",
       " 'artistic',\n",
       " 'artist',\n",
       " 'artworks',\n",
       " 'artwork',\n",
       " 'painters',\n",
       " 'paintings',\n",
       " 'artistically',\n",
       " 'painting',\n",
       " 'masterworks',\n",
       " 'impressionists',\n",
       " 'masterpieces',\n",
       " 'watercolors',\n",
       " 'painter',\n",
       " 'canvases',\n",
       " 'compositions',\n",
       " 'impressionist',\n",
       " 'abstractions',\n",
       " 'collages',\n",
       " 'frescos',\n",
       " 'painterly',\n",
       " 'watercolor',\n",
       " 'portraiture',\n",
       " 'printmaking',\n",
       " 'sculpture',\n",
       " 'sculptures',\n",
       " 'drawings',\n",
       " 'nudes',\n",
       " 'murals',\n",
       " 'sculptors',\n",
       " 'seascapes',\n",
       " 'woodcuts',\n",
       " 'expressionist',\n",
       " 'expressionistic',\n",
       " 'expressionism',\n",
       " 'expressionists',\n",
       " 'mosaics',\n",
       " 'pictorial',\n",
       " 'artsy',\n",
       " 'prints',\n",
       " 'impressionism',\n",
       " 'visual',\n",
       " 'collage',\n",
       " 'sculptural',\n",
       " 'impressionistic',\n",
       " 'abstract',\n",
       " 'creative',\n",
       " 'sculptor',\n",
       " 'painted',\n",
       " 'muses',\n",
       " 'surrealism',\n",
       " 'conceptualism',\n",
       " 'surrealist',\n",
       " 'cubism',\n",
       " 'etching',\n",
       " 'artisan',\n",
       " 'portraits',\n",
       " 'montages',\n",
       " 'cubist',\n",
       " 'lifes',\n",
       " 'renderings',\n",
       " 'artistry',\n",
       " 'landscapes',\n",
       " 'gallery',\n",
       " 'cartoonists',\n",
       " 'experimentalist',\n",
       " 'allegorical',\n",
       " 'triptych',\n",
       " 'dada',\n",
       " 'decorators',\n",
       " 'playwrights',\n",
       " 'creations',\n",
       " 'constructivist',\n",
       " 'aesthetic',\n",
       " 'sculptured',\n",
       " 'pastels',\n",
       " 'motifs',\n",
       " 'tapestries',\n",
       " 'enamels',\n",
       " 'monochrome',\n",
       " 'abstracted',\n",
       " 'artisans',\n",
       " 'needlework',\n",
       " 'exhibitions',\n",
       " 'craftsmanship',\n",
       " 'avant',\n",
       " 'minimalist',\n",
       " 'works',\n",
       " 'futurist',\n",
       " 'surrealistic',\n",
       " 'reproductions',\n",
       " 'picasso',\n",
       " 'meditations',\n",
       " 'silhouettes',\n",
       " 'minimalism',\n",
       " 'decorator',\n",
       " 'decorating']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_words[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_class = np.argmax(updated_class_weights, axis=1) == gold_labels\n",
    "correct_class[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10631772, 0.52813451, 0.        , 0.29934825, 0.        ,\n",
       "        0.06619952, 0.        , 0.        , 0.        ]),\n",
       " 3,\n",
       " array([0.04851887, 0.66976335, 0.        , 0.28171776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_class_weights[26], gold_labels[26], updated_class_weights[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 5\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_class_weights = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, init_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_class.shape, final_doc_emb.shape, updated_sent_repr.shape, updated_class_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_class_weights[0], updated_class_weights[0], gold_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_class_weights[1], updated_class_weights[1], gold_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_class_weights[2], updated_class_weights[2], gold_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_class_weights[3], updated_class_weights[3], gold_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 5\n",
    "print(padded_sent_repr.shape, sentence_mask.shape, class_repr.shape, init_doc_preds.shape)\n",
    "# padded_sent_repr = padded_sent_repr[:2]\n",
    "# sentence_mask = sentence_mask[:2]\n",
    "# init_doc_preds = init_doc_preds[:2]\n",
    "doc_to_class, doc_emb, weights = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, init_doc_preds, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"r\") as f:\n",
    "    text = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkdoc_repr = reprpickle[\"document_representations\"]\n",
    "pkdoc_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkdoc_cossim = cosine_similarity(pkdoc_repr, class_repr)\n",
    "pkdoc_classes = np.argmax(pkdoc_cossim, axis=1)\n",
    "evaluate_predictions(gold_labels, pkdoc_classes)\n",
    "evaluate_predictions(gold_labels, init_doc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_class_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_votes = np.zeros(9)\n",
    "for i in init_sent_preds[781:829]:\n",
    "    weighted_votes[i] += weights[0][19][i]\n",
    "weighted_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_doc_preds[19], doc_to_class[19], gold_labels[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_sent[19][0], doc_to_sent[19][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(init_sent_preds[781:829], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(doc_to_class == gold_labels)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 5\n",
    "print(padded_sent_repr.shape, sentence_mask.shape, class_repr.shape, init_doc_preds.shape)\n",
    "doc_to_class, doc_emb = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, init_doc_preds, new_data_path, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA on Document Embeddings & Fit GMM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained document variance: 0.9488055329297386\n"
     ]
    }
   ],
   "source": [
    "_pca = PCA(n_components=args.pca, random_state=args.random_state)\n",
    "pca_doc_repr = _pca.fit_transform(final_doc_emb)\n",
    "pca_class_repr = _pca.transform(class_repr)\n",
    "print(f\"Explained document variance: {sum(_pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.8396315789473684\n",
      "F1 macro: 0.8396297593448594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[15889, 3111], [2983, 16017]],\n",
       " 'f1_micro': 0.8396315789473684,\n",
       " 'f1_macro': 0.8396297593448594}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71955292, 0.40952983, 0.71538326, 0.72139932, 0.16384949,\n",
       "       0.66803061, 0.58444152, 0.51261272, 0.75677112, 0.18657242,\n",
       "       0.75161684, 0.73295012, 0.62532666, 0.76548129, 0.60488691,\n",
       "       0.34830207, 0.67427778, 0.71308677, 0.67438752, 0.73837452])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment][:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pseudo Training Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_dir(text, labels, prob, data_path, new_data_path):\n",
    "    assert len(text) == len(labels)\n",
    "    print(\"Saving files in:\", new_data_path)\n",
    "    \n",
    "    with open(os.path.join(new_data_path, \"dataset.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(text):\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"labels.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(labels):\n",
    "            f.write(str(line))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"probs.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(prob):\n",
    "            f.write(str(line))\n",
    "            #f.write(\",\".join(map(str, line)))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    copyfile(os.path.join(data_path, \"classes.txt\"),\n",
    "             os.path.join(new_data_path, \"classes.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(documents_to_class, prob, num_classes, cleaned_text, gold_labels, data_path, new_data_path):\n",
    "    pseudo_document_class_with_confidence = [[] for _ in range(num_classes)]\n",
    "    for i in range(documents_to_class.shape[0]):\n",
    "        pseudo_document_class_with_confidence[documents_to_class[i]].append((prob[i], i))\n",
    "\n",
    "    selected = []\n",
    "    confidence_threshold = 0.5\n",
    "    for i in range(num_classes):\n",
    "        pseudo_document_class_with_confidence[i] = sorted(pseudo_document_class_with_confidence[i], key=lambda x: x[0], reverse=True)\n",
    "        num_docs_to_take = int(len(pseudo_document_class_with_confidence[i]) * confidence_threshold)\n",
    "        confident_documents = pseudo_document_class_with_confidence[i][:num_docs_to_take]\n",
    "        confident_documents = [x[1] for x in confident_documents]\n",
    "        selected.extend(confident_documents)\n",
    "    \n",
    "    selected = sorted(selected)\n",
    "    text = [cleaned_text[i] for i in selected]\n",
    "    classes = [documents_to_class[i] for i in selected]\n",
    "    ###\n",
    "    gold_classes = [gold_labels[i] for i in selected]\n",
    "    evaluate_predictions(gold_classes, classes)\n",
    "    ###\n",
    "    # write_to_dir(text, classes, prob, data_path, new_data_path)\n",
    "    return pseudo_document_class_with_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateDataset(doc_class_assignment, doc_class_probs, num_classes, cleaned_text, gold_labels, data_path, new_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_gmm(args, document_representations, doc_class_representations, gold_labels):\n",
    "    num_classes = len(doc_class_representations)\n",
    "    cosine_similarities = cosine_similarity(document_representations, doc_class_representations)\n",
    "    doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "\n",
    "    print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "    evaluate_predictions(gold_labels, doc_class_assignment)\n",
    "\n",
    "    # initialize gmm based on these selected documents\n",
    "    document_class_assignment_matrix = np.zeros((document_representations.shape[0], num_classes))\n",
    "    for i in np.arange(len(document_representations)): # iterate through docs and sents\n",
    "        document_class_assignment_matrix[i][doc_class_assignment[i]] = 1.0\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_classes, covariance_type='tied',\n",
    "                          random_state=args.random_state,\n",
    "                          n_init=999, warm_start=True)\n",
    "\n",
    "    gmm._initialize(document_representations, document_class_assignment_matrix)\n",
    "    gmm.lower_bound_ = -np.infty\n",
    "\n",
    "    gmm.converged_ = True #HACK FOR NOT RANDOMLY INITIALIZING PARAMS DURING FIT\n",
    "    gmm.fit(document_representations)\n",
    "\n",
    "    documents_to_class = gmm.predict(document_representations)\n",
    "    confidence = gmm.predict_proba(document_representations)\n",
    "\n",
    "    print(\"Evaluate Document GMM Predictions: \")\n",
    "    evaluate_predictions(gold_labels, documents_to_class)\n",
    "\n",
    "    return documents_to_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.782384869341391\n",
      "F1 macro: 0.7704668150661399\n",
      "Evaluate Document GMM Predictions: \n",
      "F1 micro: 0.7800346930781712\n",
      "F1 macro: 0.7686244714799803\n"
     ]
    }
   ],
   "source": [
    "# 128\n",
    "doc_preds, doc_prob = doc_gmm(args, pca_doc_repr, pca_class_repr, gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bc78f6dd8c9fb4bf4049d09abbebcbc9ae8bd98d8b55b5fea020bfdbf1269a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
