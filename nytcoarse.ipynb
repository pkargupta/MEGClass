{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import re\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.decomposition import PCA\n",
    "from shutil import copyfile\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture._gaussian_mixture import _estimate_gaussian_parameters\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.dataset_name = \"20News\"\n",
    "args.gpu = 7\n",
    "args.pca = 128\n",
    "args.random_state = 42\n",
    "args.emb_dim = 768\n",
    "args.num_heads = 2\n",
    "args.batch_size = 64\n",
    "args.temp = 0.2\n",
    "args.lr = 1e-3\n",
    "args.epochs = 5\n",
    "args.accum_steps = 1\n",
    "args.max_sent = 150\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name)\n",
    "new_data_path = os.path.join(\"/home/pk36/MEGClass/intermediate_data\", args.dataset_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this is where we save all representations\n",
    "if not os.path.exists(new_data_path):\n",
    "    os.makedirs(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = os.path.join(\"/shared/data2/pk36/multidim/multigran\")\n",
    "INTERMEDIATE_DATA_FOLDER_PATH = os.path.join(\"/home/pk36/MEGClass/intermediate_data\")\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.clone().detach().cpu().numpy()\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def sentenceToClass(sent_repr, class_repr, weights):\n",
    "    # sent_repr: N x S x E\n",
    "    # class_repr: C x E\n",
    "    # weights: N x S # equals 0 for masked sentences\n",
    "\n",
    "    #cos-sim between (N x S) x E and (C x E) = N x S x C\n",
    "    m, n = sent_repr.shape[:2]\n",
    "    sentcos = cosine_similarity(sent_repr.reshape(m*n,-1), class_repr).reshape(m,n,-1)\n",
    "    sent_to_class = np.argmax(sentcos, axis=2) # N x S\n",
    "    sent_to_doc_class = np.sum(np.multiply(sent_to_class, weights), axis=1) # N x 1\n",
    "    return sent_to_doc_class\n",
    "\n",
    "def docToClass(doc_repr, class_repr):\n",
    "    # doc_repr: N x E\n",
    "    # class_repr: C x E\n",
    "\n",
    "    #cos-sim between N x E and C x E = N x C\n",
    "    doccos = cosine_similarity(doc_repr, class_repr)\n",
    "    doc_to_class = np.argmax(doccos, axis=1) # N x 1\n",
    "    return doc_to_class\n",
    "\n",
    "def evaluate_predictions(true_class, predicted_class, output_to_console=True, return_tuple=False, return_confusion=False):\n",
    "    confusion = confusion_matrix(true_class, predicted_class)\n",
    "    if return_confusion and output_to_console:\n",
    "        print(\"-\" * 80 + \"Evaluating\" + \"-\" * 80)\n",
    "        print(confusion)\n",
    "    \n",
    "    f1_micro = f1_score(true_class, predicted_class, average='micro')\n",
    "    f1_macro = f1_score(true_class, predicted_class, average='macro')\n",
    "    if output_to_console:\n",
    "        print(\"F1 micro: \" + str(f1_micro))\n",
    "        print(\"F1 macro: \" + str(f1_macro))\n",
    "    if return_tuple:\n",
    "        return confusion, f1_macro, f1_micro\n",
    "    else:\n",
    "        return {\n",
    "            \"confusion\": confusion.tolist(),\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro\n",
    "        }\n",
    "    \n",
    "def getSentClassRepr(args):\n",
    "    with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, f\"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "        dictionary = pk.load(f)\n",
    "        class_repr = dictionary[\"class_representations\"]\n",
    "        sent_repr = dictionary[\"sent_representations\"]\n",
    "    return sent_repr, class_repr\n",
    "\n",
    "\n",
    "def getDSMapAndGold(args, sent_dict):\n",
    "    # get the ground truth labels for all documents and assign a \"ground truth\" label to each sentence based on its parent document\n",
    "    gold_labels = list(map(int, open(os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"labels.txt\"), \"r\").read().splitlines()))\n",
    "    gold_sent_labels = []\n",
    "    # get all sent ids for each doc\n",
    "    doc_to_sent = []\n",
    "    sent_id = 0\n",
    "    for doc_id, doc in enumerate(sent_dict.values()):\n",
    "        sent_ids = []\n",
    "        for sent in doc:\n",
    "            sent_ids.append(sent_id)\n",
    "            gold_sent_labels.append(gold_labels[doc_id])\n",
    "            sent_id += 1\n",
    "        doc_to_sent.append(sent_ids)\n",
    "            \n",
    "    return gold_labels, gold_sent_labels, doc_to_sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-Based Sentence Embeddings, Initial Doc Embeddings, & Class Representations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceEmb(args, sent_dict, doc_to_sent, class_words, device, classonly=False):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    num_docs = len(doc_to_sent)\n",
    "    padded_sent_repr = np.zeros((num_docs, args.max_sent, args.emb_dim))\n",
    "    sentence_mask = np.ones((num_docs, args.max_sent))\n",
    "    doc_lengths = np.zeros(num_docs, dtype=int)\n",
    "    trimmed = 0\n",
    "\n",
    "    if not classonly:\n",
    "        for doc_id in tqdm(np.arange(num_docs)):\n",
    "            sents = sent_dict[str(doc_id)]\n",
    "            num_sent = len(sents)\n",
    "            if num_sent > args.max_sent:\n",
    "                trimmed += 1\n",
    "                sents = sents[:args.max_sent]\n",
    "            encoded_input = tokenizer(sents, padding=True, truncation=True, return_tensors='pt')\n",
    "            encoded_input = encoded_input.to(device)\n",
    "\n",
    "            # Compute token embeddings\n",
    "            with torch.no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "\n",
    "            # Perform pooling\n",
    "            embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "            # Normalize embeddings\n",
    "            embeddings = tensor_to_numpy(F.normalize(embeddings, p=2, dim=1))\n",
    "\n",
    "            # save the number of sentences in each document\n",
    "            doc_lengths[doc_id] = int(num_sent)\n",
    "\n",
    "            padded_sent_repr[doc_id, :embeddings.shape[0], :] = embeddings\n",
    "            # Update mask so that padded sentences are not included in attention computation\n",
    "            sentence_mask[doc_id, :num_sent] = 0\n",
    "        print(f\"Trimmed Documents: {trimmed}\")\n",
    "\n",
    "    # construct class representations\n",
    "    class_repr = np.zeros((len(class_words), args.emb_dim))\n",
    "    intro_map = {\"20News\":\"This article is about \", \"agnews\": \"This article is about \",\n",
    "                \"yelp\": \"This is \", \"nyt-coarse\":\"This article is about \", \n",
    "                \"nyt-fine\": \"This article is about \"}\n",
    "\n",
    "    print(\"Constructing Class Representations...\")\n",
    "    for class_id in tqdm(np.arange(len(class_words))):\n",
    "        # class_sent = intro_map[args.dataset_name] + \", \".join(class_words[class_id])\n",
    "        class_sent = intro_map[args.dataset_name] + class_words[class_id][0]\n",
    "        print(class_sent)\n",
    "        encoded_input = tokenizer(class_sent, truncation=True, return_tensors='pt')\n",
    "        encoded_input = encoded_input.to(device)\n",
    "         # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        # Perform pooling\n",
    "        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        # Normalize embeddings\n",
    "        embeddings = tensor_to_numpy(F.normalize(embeddings, p=2, dim=1))\n",
    "        class_repr[class_id, :] = embeddings\n",
    "    \n",
    "    if classonly:\n",
    "        return class_repr\n",
    "    else:\n",
    "        return padded_sent_repr, class_repr, doc_lengths, sentence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertSentenceEmb(args, doc_to_sent, sent_repr):\n",
    "    num_docs = len(doc_to_sent)\n",
    "    doc_lengths = np.zeros(num_docs, dtype=int)\n",
    "    # init_doc_repr = np.zeros((num_docs, args.emb_dim))\n",
    "    padded_sent_repr = np.zeros((num_docs, args.max_sent, args.emb_dim))\n",
    "    sentence_mask = np.ones((num_docs, args.max_sent))\n",
    "    trimmed = 0\n",
    "\n",
    "\n",
    "    for doc_id in tqdm(np.arange(num_docs)):\n",
    "        start_sent = doc_to_sent[doc_id][0]\n",
    "        end_sent = doc_to_sent[doc_id][-1]\n",
    "        num_sent = end_sent - start_sent + 1\n",
    "        if num_sent > args.max_sent:\n",
    "            end_sent = start_sent + args.max_sent - 1\n",
    "            num_sent = args.max_sent\n",
    "            trimmed += 1\n",
    "        embeddings = sent_repr[start_sent:end_sent+1]\n",
    "\n",
    "        # save the number of sentences in each document\n",
    "        doc_lengths[doc_id] = int(num_sent)\n",
    "\n",
    "        # Add initial doc representation\n",
    "        # init_doc_repr[doc_id, :] = np.mean(embeddings, axis=0)\n",
    "        # Add padded sentences\n",
    "        padded_sent_repr[doc_id, :embeddings.shape[0], :] = embeddings\n",
    "        # Update mask so that padded sentences are not included in attention computation\n",
    "        sentence_mask[doc_id, :num_sent] = 0\n",
    "\n",
    "    \n",
    "    print(f\"Trimmed Documents: {trimmed}\")\n",
    "\n",
    "    return padded_sent_repr, doc_lengths, sentence_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class Weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetClasses(padded_sent_repr, doc_lengths, class_repr, weights=None):\n",
    "    # weights: N x 150\n",
    "    class_weights = np.zeros((padded_sent_repr.shape[0], class_repr.shape[0])) # N x C\n",
    "    sent_weights = np.zeros(padded_sent_repr.shape[:2])\n",
    "\n",
    "    for doc_id in tqdm(np.arange(padded_sent_repr.shape[0])):\n",
    "        l = doc_lengths[doc_id]\n",
    "        sent_emb = padded_sent_repr[doc_id, :l, :] # S x E\n",
    "        sentcos = cosine_similarity(sent_emb, class_repr) # S x C\n",
    "        sent_to_class = np.argmax(sentcos, axis=1) # S\n",
    "        \n",
    "        # default: equal vote weight between all sentences\n",
    "        if weights is None:\n",
    "            # w = np.ones(doc_lengths[doc_id])/doc_lengths[doc_id]\n",
    "            # top cos-sim - second cos-sim\n",
    "            toptwo = np.partition(sentcos, -2)[:, -2:] # S x 2\n",
    "            toptwo = toptwo[:, 1] - toptwo[:, 0] # S\n",
    "            w = toptwo / np.sum(toptwo)\n",
    "            sent_weights[doc_id, :l] = w\n",
    "        else:\n",
    "            w = weights[doc_id, :l]\n",
    "        \n",
    "        class_weights[doc_id, :] = np.bincount(sent_to_class, weights=w, minlength=class_repr.shape[0])\n",
    "\n",
    "    if weights is None:\n",
    "        return class_weights, sent_weights\n",
    "    else:\n",
    "        return class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial embeddings and class representations + gold labels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"dataset.pk\"), \"rb\") as f:\n",
    "    dataset = pk.load(f)\n",
    "    sent_dict = dataset[\"sent_data\"]\n",
    "    cleaned_text = dataset[\"cleaned_text\"]\n",
    "    class_names = np.array(dataset[\"class_names\"])\n",
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "    reprpickle = pk.load(f)\n",
    "    class_words = reprpickle[\"class_words\"]\n",
    "gold_labels, gold_sent_labels, doc_to_sent = getDSMapAndGold(args, sent_dict)\n",
    "num_classes = len(class_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17871/17871 [00:00<00:00, 27721.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 127\n",
      "Constructing Class Representations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 132.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is about computer\n",
      "This article is about sports\n",
      "This article is about science\n",
      "This article is about politics\n",
      "This article is about religion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17871/17871 [00:11<00:00, 1547.60it/s]\n",
      "100%|██████████| 17871/17871 [00:07<00:00, 2485.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((17871, 150, 768), (17871,), (17871, 150), (17871, 5), (17871, 150))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_repr, class_repr = getSentClassRepr(args)\n",
    "padded_sent_repr, doc_lengths, sentence_mask = bertSentenceEmb(args, doc_to_sent, sent_repr)\n",
    "# plm_padded_sent_repr, plm_class_repr, doc_lengths, plm_sentence_mask = sentenceEmb(args, sent_dict, doc_to_sent, class_words, device)\n",
    "plm_class_repr = sentenceEmb(args, sent_dict, doc_to_sent, class_words, device, True)\n",
    "init_class_weights, init_sent_weights = getTargetClasses(padded_sent_repr, doc_lengths, class_repr, None)\n",
    "init_plm_class_weights, init_plm_sent_weights = getTargetClasses(plm_padded_sent_repr, doc_lengths, plm_class_repr, None)\n",
    "\n",
    "padded_sent_repr.shape, doc_lengths.shape, sentence_mask.shape, init_class_weights.shape, init_sent_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Re Lyme vaccine Nntp-Posting-Host ucrengr X-Newsreader TIN version 1.1 PL8 Jeff, If you have time to type it in I'd love to have the reference for that paper! thanks! -- kathleen richards email Sometimes you're the windshield, sometimes you're the bug! -dire straits\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.22120812, 0.77205911, 0.00673277, 0.        ]), 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_plm_class_weights[1], gold_labels[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Evaluate Class Weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro: 0.6967153488892619\n",
      "F1 macro: 0.6734028008214983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[4646, 71, 86, 40, 48],\n",
       "  [540, 2558, 243, 460, 178],\n",
       "  [1550, 183, 1179, 784, 256],\n",
       "  [51, 55, 44, 1886, 589],\n",
       "  [22, 16, 48, 156, 2182]],\n",
       " 'f1_micro': 0.6967153488892619,\n",
       " 'f1_macro': 0.6734028008214983}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(gold_labels, np.argmax(init_plm_class_weights, axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGClassModel(nn.Module):\n",
    "    def __init__(self, D_in, D_hidden, head, dropout=0.0):\n",
    "        super(MEGClassModel, self).__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=D_in, num_heads=head, dropout=dropout, batch_first=True)\n",
    "        self.layernorm = nn.LayerNorm(D_in)\n",
    "        # self.embd = nn.Sequential(\n",
    "        #     nn.Linear(D_in, 2*D_in),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(2*D_in, D_in))\n",
    "        self.embd = nn.Linear(D_in,D_hidden)\n",
    "        self.attention = nn.Linear(D_hidden,1)\n",
    "        \n",
    "    def forward(self, x_org, mask=None):\n",
    "        x, mha_w = self.mha(x_org,x_org,x_org,key_padding_mask=mask)\n",
    "        x = self.layernorm(x_org+x)\n",
    "        \n",
    "        x = self.embd(x)\n",
    "        x = torch.tanh(x) # contextualized sentences\n",
    "        a = self.attention(x)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill_((mask == 1).unsqueeze(-1), float('-inf'))\n",
    "        w = torch.softmax(a, dim=1) # alpha_k\n",
    "        o = torch.matmul(w.permute(0,2,1), x) #doc \n",
    "        return o, mha_w, w, x # contextualized doc, multi-head attention weights, alpha_k, contextualized sent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(sample_outputs, class_indices, class_embds, temp=0.2):\n",
    "    k = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/temp)\n",
    "    loss = -1*(torch.log(k[np.arange(len(class_indices)),class_indices]/k.sum(1))).sum()\n",
    "    return loss/len(sample_outputs)\n",
    "\n",
    "def weighted_contrastive_loss(args, sample_outputs, class_weights, class_embds):\n",
    "    # k: B x C, class_weights: B x C\n",
    "    numerator = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    denom = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    weighted_loss = -1 * (torch.log(numerator/(denom.sum(dim=1).unsqueeze(-1))) * class_weights).sum() # B x C -> B\n",
    "    # print(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)[:5])\n",
    "    # print(numerator[:5])\n",
    "    # print(denom[:5])\n",
    "    # print((torch.log(numerator/(denom.sum(dim=1).unsqueeze(-1))) * class_weights)[:5])\n",
    "    # 1/0\n",
    "    return weighted_loss/len(sample_outputs)\n",
    "\n",
    "def weighted_class_contrastive_loss(args, sample_outputs, class_weights, class_embds):\n",
    "    # numerator: B x C, class_weights: B x C\n",
    "    numerator = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    denom = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp) # * (1 - class_weights)\n",
    "    weighted_loss = -1 * (torch.log(numerator/(denom.sum(dim=1).unsqueeze(-1))) * class_weights).sum() # B x C -> B\n",
    "    # print(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)[:5])\n",
    "    # print(numerator[:5])\n",
    "    # print(denom.sum(dim=1)[:5])\n",
    "    # print((-1 * (torch.log(numerator/(denom.sum(dim=1).unsqueeze(-1))) * class_weights))[:5])\n",
    "    # 1/0\n",
    "    return weighted_loss/len(sample_outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_repr, class_weights, \n",
    "                doc_lengths, new_data_path, device):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask).to(torch.bool)\n",
    "    class_weights = torch.from_numpy(class_weights)\n",
    "    dataset = TensorDataset(sent_representations, mask, class_weights)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 768 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            model.train()\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            input_weights = batch[2].to(device).float()\n",
    "            \n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "\n",
    "            loss = weighted_class_contrastive_loss(args, c_doc, input_weights, torch.from_numpy(class_repr).float().to(device)) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(dataset_loader)\n",
    "        print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_e{args.epochs}.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    evalsampler = SequentialSampler(dataset)\n",
    "    eval_loader = DataLoader(dataset, sampler=evalsampler, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    doc_predictions = None\n",
    "    attention_weights = np.zeros_like(mask, dtype=float)\n",
    "    updated_sent_repr = np.zeros_like(sent_representations)\n",
    "    final_doc_emb = np.zeros((len(class_weights), args.emb_dim))\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "            c_sent, c_doc, alpha = tensor_to_numpy(c_sent), tensor_to_numpy(c_doc), tensor_to_numpy(torch.squeeze(alpha, dim=2))\n",
    "\n",
    "            final_doc_emb[idx:idx+c_doc.shape[0], :] = c_doc\n",
    "            attention_weights[idx:idx+c_doc.shape[0], :] = alpha\n",
    "            updated_sent_repr[idx:idx+c_doc.shape[0], :, :] = c_sent\n",
    "\n",
    "            idx += c_doc.shape[0]\n",
    "\n",
    "            doc_class = docToClass(c_doc, class_repr)\n",
    "            if doc_predictions is None:\n",
    "                doc_predictions = doc_class\n",
    "            else:\n",
    "                doc_predictions = np.append(doc_predictions, doc_class)\n",
    "    \n",
    "    updated_class_weights = getTargetClasses(updated_sent_repr, doc_lengths, class_repr, attention_weights)\n",
    "\n",
    "    return doc_predictions, final_doc_emb, updated_sent_repr, attention_weights, updated_class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:09<00:00, 28.12it/s]\n",
      " 33%|███▎      | 1/3 [00:09<00:19,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.5781413316726685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:08<00:00, 34.05it/s]\n",
      " 67%|██████▋   | 2/3 [00:18<00:08,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.086656928062439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:09<00:00, 29.36it/s]\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7707670331001282\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:16<00:00, 16.50it/s]\n",
      "100%|██████████| 17871/17871 [00:06<00:00, 2644.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sentence Transformer Embeddings + Sentence-Transformer Initial Class Distributions\n",
    "args.epochs = 3\n",
    "args.lr = 1e-3\n",
    "args.temp = 0.1\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, plm_padded_sent_repr, plm_sentence_mask, plm_class_repr, init_plm_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.718146718146718\n",
      "F1 macro: 0.6975556787502244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[4735, 58, 38, 31, 29],\n",
       "  [542, 2697, 157, 474, 109],\n",
       "  [1551, 140, 1285, 816, 160],\n",
       "  [42, 27, 29, 2002, 525],\n",
       "  [33, 16, 29, 231, 2115]],\n",
       " 'f1_micro': 0.718146718146718,\n",
       " 'f1_macro': 0.6975556787502244}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 3\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:06<00:00, 43.69it/s]\n",
      " 33%|███▎      | 1/3 [00:06<00:12,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.6032929420471191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:06<00:00, 42.62it/s]\n",
      " 67%|██████▋   | 2/3 [00:12<00:06,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.1564592123031616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:06<00:00, 43.52it/s]\n",
      "100%|██████████| 3/3 [00:19<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.8360235095024109\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:10<00:00, 26.27it/s]\n",
      "100%|██████████| 17871/17871 [00:06<00:00, 2863.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sentence Transformer Embeddings + Class-Oriented Initial Class Distributions\n",
    "args.epochs = 3\n",
    "args.lr = 1e-3\n",
    "args.temp = 0.1\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, plm_padded_sent_repr, plm_sentence_mask, plm_class_repr, init_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7877007442224834\n",
      "F1 macro: 0.7758593030310905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[4753, 24, 85, 25, 4],\n",
       "  [228, 3499, 85, 162, 5],\n",
       "  [1450, 116, 1846, 527, 13],\n",
       "  [50, 84, 154, 2046, 291],\n",
       "  [58, 24, 160, 249, 1933]],\n",
       " 'f1_micro': 0.7877007442224834,\n",
       " 'f1_macro': 0.7758593030310905}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 3\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Class Weights:  [0.35916079 0.64083921]\n",
      "Updated Class Weights:  [0.09076648 0.90923354]\n",
      "True Class:  0\n",
      "good ([-0.067625    0.19165149]) 0.029811829328536987: ok!\n",
      "bad ([-0.0163843  -0.03797249]) 0.09076648205518723: let me tell you about my bad experience first.\n",
      "good ([-0.17282255  0.13541248]) 0.021152541041374207: i went to d b last night for a post wedding party - which, side note, is a great idea!\n",
      "good ([-0.00954034  0.01940415]) 0.07051163166761398: it was around midnight and the bar wasn't really populated.\n",
      "good ([-0.01856739  0.03315905]) 0.04901992529630661: there were three bartenders and only one was actually making rounds to see if anyone needed anything.\n",
      "good ([-0.11018234  0.01576056]) 0.03178786486387253: the two other bartenders were chatting on the far side of the bar that no one was sitting at.\n",
      "good ([0.00839888 0.05479983]) 0.07281240820884705: kind of counter productive if you ask me.\n",
      "good ([-0.02061332  0.01664088]) 0.036122485995292664: i stood there for about 5 minutes, which for a busy bar is fine but when i am the only one with my card out then, it just seems a little ridiculous.\n",
      "good ([-0.07144883  0.05047384]) 0.03886718302965164: i made eye contact with the one girl twice and gave her a smile and she literally turned away.\n",
      "good ([-0.10750484  0.06433732]) 0.022364487871527672: i finally had to walk to them to get their attention.\n",
      "good ([-0.15142745  0.10266646]) 0.01875869370996952: i was standing right in front of them smiling and they didn't ask if i need anything.\n",
      "good ([-0.06602135  0.08989366]) 0.04049403965473175: i finally said, \"are you working? \"\n",
      "good ([-0.09780755 -0.02114648]) 0.04570158198475838: and they gave each other a weird look.\n",
      "good ([-0.05316153  0.05905497]) 0.02777610719203949: i felt like i was the crazy one.\n",
      "good ([-0.14250279  0.09732946]) 0.028337841853499413: i asked for a beer got the beer.\n",
      "good ([-0.10118166  0.06338516]) 0.0356903038918972: in between that time, the other bartender brought food over and set it down.\n",
      "good ([-0.06752293  0.01905084]) 0.047956015914678574: she took a fry from the plate (right in front of me) and then served it to someone on the other side of the bar.\n",
      "good ([-0.00457467  0.07819455]) 0.036331161856651306: what the hell!\n",
      "good ([-0.02661865  0.01051561]) 0.056954242289066315: i felt like i was in some grimy bar in out in the sticks - not an established d b. i was just really turned off from that experience.\n",
      "good ([-0.05566075  0.02521952]) 0.05573747679591179: the good is that d b provides a different type of entertainment when you want to mix things up.\n",
      "good ([-0.19892203  0.16190209]) 0.014333393424749374: i remember going here with my grandparents when i was a kid and it was the best treat ever!\n",
      "good ([-0.10977217  0.096536  ]) 0.023829583078622818: we would eat at the restaurant and then spend hours playing games.\n",
      "good ([-0.16094368  0.16124834]) 0.022534793242812157: this place holds some really good memories for me.\n",
      "good ([-0.02734696  0.01015433]) 0.08234794437885284: it's a shame that my experience last night has spoiled the high standards i held for it.\n"
     ]
    }
   ],
   "source": [
    "doc_id = 7\n",
    "print(\"Initial Class Weights: \", init_class_weights[doc_id])\n",
    "print(\"Updated Class Weights: \", updated_class_weights[doc_id])\n",
    "print(\"True Class: \", gold_labels[doc_id])\n",
    "tok_sents = sent_dict[str(doc_id)]\n",
    "chosen_class = np.argmax(cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr), axis=1)\n",
    "sent_classes = cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr)\n",
    "\n",
    "for s,c,cw,w in zip(tok_sents, class_names[chosen_class.astype(int)], sent_classes, updated_sent_weights[doc_id, :len(tok_sents)]):\n",
    "    print(f'{c} ({cw}) {w}: {s}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pseudo-Training Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pca = PCA(n_components=args.pca, random_state=args.random_state)\n",
    "pca_doc_repr = _pca.fit_transform(final_doc_emb)\n",
    "pca_class_repr = _pca.transform(class_repr)\n",
    "print(f\"Explained document variance: {sum(_pca.explained_variance_ratio_)}\")\n",
    "cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)\n",
    "\n",
    "# get cleaned text\n",
    "cleaned_text = dataset[\"cleaned_text\"]\n",
    "\n",
    "# generate pseudo training dataset\n",
    "generateDataset(doc_class_assignment, doc_class_probs, num_classes, cleaned_text, gold_labels, data_path, new_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secretary_general_kofi_annan said today that iraq has cooperated up to now with united_nations weapons inspectors , so it would be ''premature'' to take military action before inspectors report back on their investigations to the security_council on jan . 27 .\n",
      "of all those expelled , mr . hogan is putting up the biggest fight against the restrictions , asking a federal_judge to overrule the board and mounting a public_relations battle .\n",
      "the school plans to offer scholarships for families who cannot afford tuition , ms . friedman said .\n",
      "''we 've had to deal with very serious issues , '' mr . mccartney said .\n",
      "it also came as china has worked hard to strengthen ties with the bush_administration .\n",
      "''the american administration is trying to create some pretexts to attack iraq , to exercise their aggression against iraq , '' he said .\n",
      "an adviser to mr . edwards said that campaign had deliberately chosen the day after new year 's to go on ''today , '' because the senator 's aides figured , correctly , that not much else would be going on and that the questions in that morning forum would be something less than fierce .\n",
      "''i feel tremendous support for the physicians who have walked out , '' said dr . joe endrich , an internist and the chairman of the board of the weirton medical center .\n",
      "sir edward said he expected consumer_spending and inflation in housing prices to ease without a crash in the booming real_estate market .\n",
      "on long_island , brokers say , the decorating trend is changing , with the formality of contemporary design and its vast white areas highlighted with modernistic steel shapes yielding to the details , colors and informality of the traditional style .\n"
     ]
    }
   ],
   "source": [
    "topsentids = np.argmax(updated_sent_weights, axis=1)\n",
    "for idx in np.arange(10):\n",
    "    print(sent_dict[str(idx)][topsentids[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find really confident sentences\n",
    "def getConfidentSent(weights, sent_emb, class_repr):\n",
    "    topsentids = np.argmax(weights, axis=1)\n",
    "    topembs = np.zeros((sent_emb.shape[0], sent_emb.shape[2]))\n",
    "    for doc_id in np.arange(sent_emb.shape[0]):\n",
    "        topembs[doc_id, :] = sent_emb[doc_id, topsentids[doc_id], :]\n",
    "\n",
    "    topcossim = cosine_similarity(topembs, class_repr) # N x C\n",
    "    toppreds = np.argmax(topcossim, axis=1)\n",
    "    class_sents = [[] for c in range(class_repr.shape[0])]\n",
    "\n",
    "    for id, p in enumerate(toppreds):\n",
    "        # doc id, sent id, sent weight, sent emb\n",
    "        class_sents[p].append((id, topsentids[id], weights[id, topsentids[id]], topembs[id]))\n",
    "    for c in np.arange(len(class_sents)):\n",
    "        total = int(len(class_sents[c])*0.05)\n",
    "        class_sents[c] = sorted(class_sents[c], key=lambda x: x[2], reverse=True)[:total]\n",
    "\n",
    "    return class_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sents = getConfidentSent(init_class_weights, padded_sent_repr, class_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1.0000000000000002 1.0000000000000002\n",
      "the wpp group 's acquisition of the struggling british advertising company cordiant communications group may not be a done deal after all .\n",
      "625\n",
      "1.0000000000000007 1.0000000000000004\n",
      "he told them , aides said , that he wanted to hold a full scale news conference a few hours later .\n",
      "111\n",
      "1.0000000000000002 1.0000000000000002\n",
      "kiplagat , born in kenya , finished third in new york last year .\n",
      "69\n",
      "1.0000000000000002 1.0000000000000002\n",
      "if a scheduled appointment was missed , the health visitor would make a home visit to make sure all was well and to ensure that appointments for checkups and immunizations were kept .\n",
      "75\n",
      "1.0000000000000002 1.0000000000000002\n",
      "more than half of private_school students attend catholic schools , while about a third are enrolled in other religious schools .\n",
      "85\n",
      "1.0000000000000002 1.0000000000000002\n",
      "ft . co op in a loft building elevator , dining_room , den , office , high ceilings , renovated_kitchen , 3 exposures maintenance 1 , 600 , 50 tax deductible , listed at 895 , 000 , 26 weeks on market ( brokers kingman associates stribling wells gay ) tribeca 415 , 000 303 greenwich_street 3 bedroom , 2 1 2 bath , 1 , 300 sq .\n",
      "32\n",
      "0.9997138728619483 0.9993279772161112\n",
      "page_a10 .\n",
      "19\n",
      "0.9947409088024326 0.9926826316690256\n",
      "everything we did just sort of fascinated them . \"\n",
      "60\n",
      "1.0 0.999388076679609\n",
      "'s top weapons inspector , with mr . bush arguing that it demonstrated he was ''right to take action'' in iraq despite its findings that saddam_hussein had eliminated stockpiles of illicit_weapons years before the invasion .\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_sents)):\n",
    "    print(len(class_sents[i]))\n",
    "    top = class_sents[i][1]\n",
    "    print(class_sents[i][0][2], class_sents[i][1][2])\n",
    "    print(sent_dict[str(top[0])][top[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7704210526315789\n",
      "F1 macro: 0.7610170669333791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[10869, 8131], [593, 18407]],\n",
       " 'f1_micro': 0.7704210526315789,\n",
       " 'f1_macro': 0.7610170669333791}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 4, class-oriented + new loss\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[-0.7307, -0.7865],\n",
    "        [-1.4249, -0.0000],\n",
    "        [-1.0388, -0.4371],\n",
    "        [-0.7478, -0.8558],\n",
    "        [-0.3418, -1.1477]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47846081, 0.52153919],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7036531 , 0.2963469 ],\n",
       "       ...,\n",
       "       [0.16955682, 0.83044318],\n",
       "       [1.        , 0.        ],\n",
       "       [0.71302977, 0.28697023]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " array([ True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc_pred == gold_labels)[:10], (gold_labels == np.argmax(init_class_weights, axis=1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 150)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_sent_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.60it/s]\n",
      " 20%|██        | 1/5 [00:17<01:09, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.2325527667999268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 27.78it/s]\n",
      " 40%|████      | 2/5 [00:35<00:53, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7424776554107666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 27.63it/s]\n",
      " 60%|██████    | 3/5 [00:53<00:35, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3872785270214081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.08it/s]\n",
      " 80%|████████  | 4/5 [01:11<00:17, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3500744700431824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 27.44it/s]\n",
      "100%|██████████| 5/5 [01:29<00:00, 17.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3379160463809967\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:19<00:00, 25.61it/s]\n",
      "100%|██████████| 31997/31997 [00:15<00:00, 2073.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.8020439416195269\n",
      "F1 macro: 0.6456836188505892\n"
     ]
    }
   ],
   "source": [
    "# Second Iteration:\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, updated_sent_repr, sentence_mask, class_repr, updated_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "    reprpickle = pk.load(f)\n",
    "    class_words = reprpickle[\"class_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'great',\n",
       " 'excellent',\n",
       " 'fantastic',\n",
       " 'terrific',\n",
       " 'wonderful',\n",
       " 'superb',\n",
       " 'amazing',\n",
       " 'incredible',\n",
       " 'fabulous',\n",
       " 'awesome',\n",
       " 'outstanding',\n",
       " 'stellar',\n",
       " 'phenomenal',\n",
       " 'marvelous',\n",
       " 'exceptional',\n",
       " 'excellently',\n",
       " 'splendid',\n",
       " 'tremendous',\n",
       " 'delicious',\n",
       " 'superbly',\n",
       " 'wonderfully',\n",
       " 'perfect',\n",
       " 'fantastically',\n",
       " 'delightful',\n",
       " 'lovely',\n",
       " 'fabulously',\n",
       " 'awesomeness',\n",
       " 'greatness',\n",
       " 'gorgeous',\n",
       " 'magnificent',\n",
       " 'spectacular',\n",
       " 'extraordinary',\n",
       " 'beautifully',\n",
       " 'brilliant',\n",
       " 'beautiful',\n",
       " 'sublime',\n",
       " 'stunning',\n",
       " 'amazingly',\n",
       " 'sensational',\n",
       " 'masterful',\n",
       " 'perfectly',\n",
       " 'exquisite',\n",
       " 'divine',\n",
       " 'best',\n",
       " 'deliciously',\n",
       " 'fine',\n",
       " 'decent',\n",
       " 'superlative',\n",
       " 'glorious',\n",
       " 'amazingness',\n",
       " 'awesomely',\n",
       " 'impeccable',\n",
       " 'heavenly',\n",
       " 'adequate',\n",
       " 'tasty',\n",
       " 'deliciousness',\n",
       " 'yummy',\n",
       " 'pleasing',\n",
       " 'delectable',\n",
       " 'nice',\n",
       " 'passable',\n",
       " 'unique',\n",
       " 'tasteful',\n",
       " 'kickass',\n",
       " 'delightfully',\n",
       " 'nicely',\n",
       " 'perfection',\n",
       " 'wholesome',\n",
       " 'interesting',\n",
       " 'impressive',\n",
       " 'abundant',\n",
       " 'decently',\n",
       " 'serviceable',\n",
       " 'masterfully',\n",
       " 'killer',\n",
       " 'exceptionally',\n",
       " 'flawlessly',\n",
       " 'huge',\n",
       " 'unbelievable',\n",
       " 'uniqueness',\n",
       " 'remarkable',\n",
       " 'flawless',\n",
       " 'satisfactory',\n",
       " 'standout',\n",
       " 'ideal',\n",
       " 'outrageously',\n",
       " 'massive',\n",
       " 'finest',\n",
       " 'artful',\n",
       " 'impressively',\n",
       " 'superior',\n",
       " 'enormous',\n",
       " 'fresh',\n",
       " 'immaculate',\n",
       " 'immaculately',\n",
       " 'pleasant',\n",
       " 'alluring',\n",
       " 'aweful',\n",
       " 'generously']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_class = np.argmax(updated_class_weights, axis=1) == gold_labels\n",
    "correct_class[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10631772, 0.52813451, 0.        , 0.29934825, 0.        ,\n",
       "        0.06619952, 0.        , 0.        , 0.        ]),\n",
       " 3,\n",
       " array([0.04851887, 0.66976335, 0.        , 0.28171776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_class_weights[26], gold_labels[26], updated_class_weights[26]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA on Document Embeddings & Fit GMM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained document variance: 0.8698887026923976\n"
     ]
    }
   ],
   "source": [
    "_pca = PCA(n_components=args.pca, random_state=args.random_state)\n",
    "pca_doc_repr = _pca.fit_transform(final_doc_emb)\n",
    "# pca_doc_repr = _pca.fit_transform(np.sum(padded_sent_repr, axis=1)/doc_lengths.reshape((-1, 1)))\n",
    "pca_class_repr = _pca.transform(plm_class_repr)\n",
    "print(f\"Explained document variance: {sum(_pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.8009624531363662\n",
      "F1 macro: 0.7875096605942187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[4586, 61, 162, 60, 22],\n",
       "  [78, 3645, 66, 174, 16],\n",
       "  [1063, 194, 1959, 701, 35],\n",
       "  [28, 73, 100, 2087, 337],\n",
       "  [23, 19, 118, 227, 2037]],\n",
       " 'f1_micro': 0.8009624531363662,\n",
       " 'f1_macro': 0.7875096605942187}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-oriented final doc\n",
    "cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.8893947368421051\n",
      "F1 macro: 0.8893947349271942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[16901, 2099], [2104, 16896]],\n",
       " 'f1_micro': 0.8893947368421051,\n",
       " 'f1_macro': 0.8893947349271942}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-oriented average\n",
    "cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pseudo Training Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_dir(text, labels, prob, data_path, new_data_path):\n",
    "    assert len(text) == len(labels)\n",
    "    print(\"Saving files in:\", new_data_path)\n",
    "    \n",
    "    with open(os.path.join(new_data_path, \"dataset.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(text):\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"labels.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(labels):\n",
    "            f.write(str(line))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"probs.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(prob):\n",
    "            f.write(str(line))\n",
    "            #f.write(\",\".join(map(str, line)))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    copyfile(os.path.join(data_path, \"classes.txt\"),\n",
    "             os.path.join(new_data_path, \"classes.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(documents_to_class, prob, num_classes, cleaned_text, gold_labels, data_path, new_data_path):\n",
    "    pseudo_document_class_with_confidence = [[] for _ in range(num_classes)]\n",
    "    for i in range(documents_to_class.shape[0]):\n",
    "        pseudo_document_class_with_confidence[documents_to_class[i]].append((prob[i], i))\n",
    "\n",
    "    selected = []\n",
    "    confidence_threshold = 0.5\n",
    "    confident_documents = [[] for _ in range(num_classes)]\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        pseudo_document_class_with_confidence[i] = sorted(pseudo_document_class_with_confidence[i], key=lambda x: x[0], reverse=True)\n",
    "        num_docs_to_take = int(len(pseudo_document_class_with_confidence[i]) * confidence_threshold)\n",
    "        confident_documents[i] = pseudo_document_class_with_confidence[i][:num_docs_to_take]\n",
    "        selected.extend([x[1] for x in confident_documents[i]])\n",
    "    \n",
    "    selected = sorted(selected)\n",
    "    text = [cleaned_text[i] for i in selected]\n",
    "    classes = [documents_to_class[i] for i in selected]\n",
    "    probs = [prob[i] for i in selected]\n",
    "    ###\n",
    "    gold_classes = [gold_labels[i] for i in selected]\n",
    "    evaluate_predictions(gold_classes, classes)\n",
    "    ###\n",
    "    write_to_dir(text, classes, probs, data_path, new_data_path)\n",
    "    return confident_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro: 0.8843743004253414\n",
      "F1 macro: 0.8703795616370998\n",
      "Saving files in: /home/pk36/MEGClass/intermediate_data/20News\n"
     ]
    }
   ],
   "source": [
    "finalconf = generateDataset(doc_class_assignment, doc_class_probs, num_classes, cleaned_text, gold_labels, data_path, new_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I've been waiting for an order for 6 weeks. That would be fine if customer service let me know there would be a delay, but I've contacted them 5 times for updates and so far nothing, other than passing the buck and telling me that the product was to be drop shipped by another company. Since I'm in the business of customer service, I found their non-response unacceptable. I'll update the review if there are new developments. I do not like to trash any business so am hoping they redeem themselves. Update from 10 17. Ally from Muscle Driver just called. The product finally shipped from Fisher. I have a tracking number. Still no excuse for the long wait, but good damage control. Update on 10 22. The lack of communication between Fisher and Muscle Driver is astounding. Fisher sent our package through some private delivery service (not UPS, Fedex, or USPS) and they only do curbside delivery and won't give us a window so now I need to take a day off to make sure I can get the package that I should have received a month ago.\",\n",
       " 1,\n",
       " 0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[23973], doc_class_assignment[23973], gold_labels[23973]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6838244497723575"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalprobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_gmm(args, document_representations, doc_class_representations, gold_labels):\n",
    "    num_classes = len(doc_class_representations)\n",
    "    cosine_similarities = cosine_similarity(document_representations, doc_class_representations)\n",
    "    doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "\n",
    "    print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "    evaluate_predictions(gold_labels, doc_class_assignment)\n",
    "\n",
    "    # initialize gmm based on these selected documents\n",
    "    document_class_assignment_matrix = np.zeros((document_representations.shape[0], num_classes))\n",
    "    for i in np.arange(len(document_representations)): # iterate through docs and sents\n",
    "        document_class_assignment_matrix[i][doc_class_assignment[i]] = 1.0\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_classes, covariance_type='tied',\n",
    "                          random_state=args.random_state,\n",
    "                          n_init=999, warm_start=True)\n",
    "\n",
    "    gmm._initialize(document_representations, document_class_assignment_matrix)\n",
    "    gmm.lower_bound_ = -np.infty\n",
    "\n",
    "    gmm.converged_ = True #HACK FOR NOT RANDOMLY INITIALIZING PARAMS DURING FIT\n",
    "    gmm.fit(document_representations)\n",
    "\n",
    "    documents_to_class = gmm.predict(document_representations)\n",
    "    confidence = gmm.predict_proba(document_representations)\n",
    "\n",
    "    print(\"Evaluate Document GMM Predictions: \")\n",
    "    evaluate_predictions(gold_labels, documents_to_class)\n",
    "\n",
    "    return documents_to_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.782384869341391\n",
      "F1 macro: 0.7704668150661399\n",
      "Evaluate Document GMM Predictions: \n",
      "F1 micro: 0.7800346930781712\n",
      "F1 macro: 0.7686244714799803\n"
     ]
    }
   ],
   "source": [
    "# 128\n",
    "doc_preds, doc_prob = doc_gmm(args, pca_doc_repr, pca_class_repr, gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bc78f6dd8c9fb4bf4049d09abbebcbc9ae8bd98d8b55b5fea020bfdbf1269a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
