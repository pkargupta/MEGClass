{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from representations import sentenceEmb, contextualizedEmb\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.dataset_name = \"agnews\"\n",
    "args.gpu = 2\n",
    "args.pca = 64\n",
    "args.emb_dim = 768\n",
    "args.num_heads = 2\n",
    "args.batch_size = 64\n",
    "args.epochs = 5\n",
    "args.accum_steps = 1\n",
    "args.max_sent = 150\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"dataset.txt\")\n",
    "new_data_path = os.path.join(\"/home/pk36/MEGClass/intermediate_data\", args.dataset_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this is where we save all representations\n",
    "if not os.path.exists(new_data_path):\n",
    "    os.makedirs(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sentence Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 61779/120000 [09:32<09:07, 106.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right mark without Left:  $2,137,000 and Counting. David Gardner launches our Foolanthropy campaign for 2004.\" /&gt;                               Fool.com:  $2,137,000 and Counting Foolanthropy          &lt;META Name=\"ArticleDate\" Content=\"2004/10/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 63818/120000 [09:52<08:30, 109.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right mark without Left: Biotech's 5 Baggers. How can yesterday's biotech winners lead you to today's top performers?\" /&gt;                                 Fool.com: Biotech's 5 Baggers Commentary October 18, 2004   &lt;script language=\"JavaScript\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [18:29<00:00, 108.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 0\n",
      "Retrieved Class Representations!\n"
     ]
    }
   ],
   "source": [
    "padded_sent_representations, sentence_mask, class_repr = sentenceEmb(args, data_path, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), (120000, 150, 768))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sent_representations.dtype, padded_sent_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('bool'), (120000, 150), dtype('float64'), (4, 768))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_mask.dtype, sentence_mask.shape, class_repr.dtype, class_repr.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarities between Sentences and Docs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_embeddings(emb_a, emb_b):\n",
    "    return np.dot(emb_a, np.transpose(emb_b)) / np.outer(np.linalg.norm(emb_a, axis=1), np.linalg.norm(emb_b, axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEGClass Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGClassModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
    "        #super().__init__(config)\n",
    "        super(MEGClassModel, self).__init__()\n",
    "\n",
    "        self.attention  = torch.nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)\n",
    "        # Two-layer MLP\n",
    "        self.ffn1 = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2*emb_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2*emb_dim, emb_dim)\n",
    "        )\n",
    "        self.ffn2 = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        self.sent_attention = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "            )\n",
    "    \n",
    "    def forward(self, input_emb, mask=None):\n",
    "        # input_emb: batch size x sequence length x emb_dim\n",
    "        X, _ = self.attention(input_emb, input_emb, input_emb, key_padding_mask=mask)\n",
    "        X = X + input_emb\n",
    "        X = self.ffn2(X)\n",
    "        contextualized_sent = self.norm1(X) #[~mask] N x S x E\n",
    "\n",
    "        # convert mask from N x S to N x S x E\n",
    "        full_mask = (~mask).unsqueeze(-1).expand(X.size())\n",
    "        exp_sent = torch.exp(self.sent_attention(contextualized_sent)) # N x S x E\n",
    "        denom = torch.unsqueeze(torch.sum(exp_sent * (full_mask).int().float(), dim=1), dim=1) # N x 1 x E\n",
    "        contextualized_doc = torch.sum((torch.div(exp_sent, denom) * contextualized_sent) * (full_mask), dim=1) # N x 1 x E\n",
    "\n",
    "        return contextualized_sent, contextualized_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxClass(class_repr, doc_repr, labels=None, confident=False):\n",
    "    # labels (N x C): each row has either one class with a value = 1 OR all rows are zero meaning not confident enough\n",
    "\n",
    "    class_repr = F.normalize(class_repr, dim=1) # C x emb_dim\n",
    "    doc_repr = F.normalize(doc_repr, dim=1) # N x emb_dim\n",
    "\n",
    "    # cosine similarity between doc_repr and class_repr\n",
    "    cos_sim = torch.mm(doc_repr, class_repr.transpose(0,1)) # N x C\n",
    "\n",
    "    if labels is None:\n",
    "        # identify closest class i to doc\n",
    "        i_sim = torch.max(cos_sim, dim=1)[0] # N x 1\n",
    "    elif (not confident) and (labels is not None):\n",
    "        i_sim = cos_sim[labels]\n",
    "    else:\n",
    "        # get the confident class cos-sim OR get the max cos-sim (1 if no confident class, 0 if yes)\n",
    "        i_sim = torch.max(cos_sim * labels, dim=1)[0] + (1 - torch.sum(labels, dim=1)) * torch.max(cos_sim, dim=1)[0]\n",
    "    \n",
    "    return i_sim\n",
    "    \n",
    "\n",
    "def contrastive_loss(class_repr, doc_repr, i_sim, temp=0.2):\n",
    "    class_repr = F.normalize(class_repr, dim=1) # C x emb_dim\n",
    "    doc_repr = F.normalize(doc_repr, dim=1) # N x emb_dim\n",
    "\n",
    "    # cosine similarity between doc_repr and class_repr\n",
    "    cos_sim = torch.mm(doc_repr, class_repr.transpose(0,1)) # N x C\n",
    "\n",
    "    # compute loss\n",
    "    loss = -torch.log((torch.exp(i_sim)/temp)/torch.sum(torch.exp(cos_sim/temp), dim=1))\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.clone().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_repr, new_data_path, device, gold_labels):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    dataset = TensorDataset(sent_representations, mask)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 1024 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        model.zero_grad()\n",
    "        for j, batch in enumerate(tqdm(dataset_loader)):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            \n",
    "            c_sent, c_doc = model(input_emb, mask=input_mask)\n",
    "\n",
    "            i_sim = findMaxClass(torch.from_numpy(class_repr).float().to(device), c_doc)\n",
    "\n",
    "            loss = contrastive_loss(torch.from_numpy(class_repr).float().to(device), c_doc, i_sim) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = torch.tensor([total_train_loss / len(dataset_loader) * args.accum_steps])\n",
    "        print(f\"Average training loss: {avg_train_loss.mean()}\")\n",
    "\n",
    "    model.eval()\n",
    "    context_sent = None\n",
    "    context_doc = None\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_weights.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    #sentence_predictions = []\n",
    "    #doc_predictions = []\n",
    "\n",
    "    with torch.no_grad(), open(os.path.join(new_data_path, \"contextualized_sent.txt\"), 'w') as fs, open(os.path.join(new_data_path, \"contextualized_docs.txt\"), 'w') as fd:\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_sent, c_doc = model(input_emb, mask=input_mask)\n",
    "            c_sent = tensor_to_numpy(c_sent)\n",
    "            c_doc = tensor_to_numpy(c_doc)\n",
    "\n",
    "            # fs.write(str(c_sent))\n",
    "            # fs.write(\"\\n\")\n",
    "\n",
    "            # fd.write(str(c_doc))\n",
    "            # fd.write(\"\\n\")\n",
    "\n",
    "            #sent_class = cosine_similarity_embeddings(c_sent, class_repr)\n",
    "            #doc_class = \n",
    "\n",
    "            # if context_sent is None:\n",
    "            #     context_sent = c_sent\n",
    "            #     context_doc = c_doc\n",
    "            # else:\n",
    "            #     context_sent = torch.cat((context_sent, c_sent), dim=0)\n",
    "            #     context_doc = torch.cat((context_doc, c_doc), dim=0)\n",
    "\n",
    "    # return tensor_to_numpy(context_sent), tensor_to_numpy(context_doc), class_repr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Contextualized Embedding Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:09<00:00, 26.89it/s]\n",
      " 20%|██        | 1/5 [01:09<04:38, 69.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.32817596197128296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:08<00:00, 27.25it/s]\n",
      " 40%|████      | 2/5 [02:18<03:27, 69.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.3425796329975128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.06it/s]\n",
      " 60%|██████    | 3/5 [03:30<02:21, 70.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.38553935289382935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:10<00:00, 26.72it/s]\n",
      " 80%|████████  | 4/5 [04:40<01:10, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.45694342255592346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.37it/s]\n",
      "100%|██████████| 5/5 [05:52<00:00, 70.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.5571542978286743\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:09<00:00, 26.84it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m/shared/data2/pk36/multidim/multigran\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m.\u001b[39mdataset_name, \u001b[39m\"\u001b[39m\u001b[39mlabels.txt\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m l:\n\u001b[1;32m      2\u001b[0m     gold_labels \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()\n\u001b[0;32m----> 4\u001b[0m csent, cdoc, class_repr \u001b[39m=\u001b[39m contextEmb(args, padded_sent_representations, sentence_mask, class_repr, new_data_path, device, gold_labels)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"labels.txt\"), \"r\") as l:\n",
    "    gold_labels = l.read().splitlines()\n",
    "\n",
    "csent, cdoc, class_repr = contextEmb(args, padded_sent_representations, sentence_mask, class_repr, new_data_path, device, gold_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_embedding(cdoc, class_re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bc78f6dd8c9fb4bf4049d09abbebcbc9ae8bd98d8b55b5fea020bfdbf1269a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
