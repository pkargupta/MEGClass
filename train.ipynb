{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from representations import sentenceEmb, contextualizedEmb\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import re\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.dataset_name = \"agnews\"\n",
    "args.gpu = 2\n",
    "args.pca = 64\n",
    "args.emb_dim = 768\n",
    "args.num_heads = 2\n",
    "args.batch_size = 64\n",
    "args.epochs = 5\n",
    "args.accum_steps = 1\n",
    "args.max_sent = 150\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"dataset.txt\")\n",
    "new_data_path = os.path.join(\"/home/pk36/MEGClass/intermediate_data\", args.dataset_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this is where we save all representations\n",
    "if not os.path.exists(new_data_path):\n",
    "    os.makedirs(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sentence Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 61780/120000 [15:47<14:55, 65.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right mark without Left:  $2,137,000 and Counting. David Gardner launches our Foolanthropy campaign for 2004.\" /&gt;                               Fool.com:  $2,137,000 and Counting Foolanthropy          &lt;META Name=\"ArticleDate\" Content=\"2004/10/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 63805/120000 [16:18<14:34, 64.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right mark without Left: Biotech's 5 Baggers. How can yesterday's biotech winners lead you to today's top performers?\" /&gt;                                 Fool.com: Biotech's 5 Baggers Commentary October 18, 2004   &lt;script language=\"JavaScript\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [30:48<00:00, 64.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 0\n",
      "Retrieved Class Representations!\n"
     ]
    }
   ],
   "source": [
    "padded_sent_representations, sentence_mask, class_repr = sentenceEmb(args, data_path, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), (120000, 150, 768))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sent_representations.dtype, padded_sent_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('bool'), (120000, 150), dtype('float64'), (4, 768))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_mask.dtype, sentence_mask.shape, class_repr.dtype, class_repr.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.clone().detach().cpu().numpy()\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def getClassRepr(args, load=True):\n",
    "    with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, f\"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "        dictionary = pk.load(f)\n",
    "        class_representations = dictionary[\"class_representations\"]\n",
    "    return class_representations\n",
    "\n",
    "# Given tensor representations for classes and documents, identify the top class\n",
    "def findMaxClass(class_repr, doc_repr, labels=None, confident=False):\n",
    "    # labels (N x C): each row has either one class with a value = 1 OR all rows are zero meaning not confident enough\n",
    "\n",
    "    class_repr = F.normalize(class_repr, dim=1) # C x emb_dim\n",
    "    doc_repr = F.normalize(doc_repr, dim=1) # N x emb_dim\n",
    "\n",
    "    # cosine similarity between doc_repr and class_repr\n",
    "    cos_sim = torch.mm(doc_repr, class_repr.transpose(0,1)) # N x C\n",
    "\n",
    "    if labels is None:\n",
    "        # identify closest class i to doc\n",
    "        i_sim = torch.max(cos_sim, dim=1)[0] # N x 1\n",
    "    elif (not confident) and (labels is not None):\n",
    "        i_sim = cos_sim[labels]\n",
    "    else:\n",
    "        # get the confident class cos-sim OR get the max cos-sim (1 if no confident class, 0 if yes)\n",
    "        i_sim = torch.max(cos_sim * labels, dim=1)[0] + (1 - torch.sum(labels, dim=1)) * torch.max(cos_sim, dim=1)[0]\n",
    "    \n",
    "    return i_sim\n",
    "\n",
    "def contrastive_loss(class_repr, doc_repr, i_sim, temp=0.2):\n",
    "    class_repr = F.normalize(class_repr, dim=1) # C x emb_dim\n",
    "    doc_repr = F.normalize(doc_repr, dim=1) # N x emb_dim\n",
    "\n",
    "    # cosine similarity between doc_repr and class_repr\n",
    "    cos_sim = torch.mm(doc_repr, class_repr.transpose(0,1)) # N x C\n",
    "\n",
    "    # compute loss\n",
    "    loss = -torch.log((torch.exp(i_sim)/temp)/torch.sum(torch.exp(cos_sim/temp), dim=1))\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def cosine_similarity_embeddings(emb_a, emb_b):\n",
    "    return np.dot(emb_a, np.transpose(emb_b)) / np.outer(np.linalg.norm(emb_a, axis=1), np.linalg.norm(emb_b, axis=1))\n",
    "\n",
    "def sentenceToClass(sent_repr, class_repr, weights):\n",
    "    # sent_repr: N x S x E\n",
    "    # class_repr: C x E\n",
    "    # weights: N x S # equals 0 for masked sentences\n",
    "\n",
    "    #cos-sim between (N x S) x E and (C x E) = N x S x C\n",
    "    m, n = sent_repr.shape[:2]\n",
    "    sentcos = cosine_similarity(sent_repr.reshape(m*n,-1), class_repr).reshape(m,n,-1)\n",
    "    sent_to_class = np.argmax(sentcos, axis=2) # N x S\n",
    "    sent_to_doc_class = np.sum(np.multiply(sent_to_class, weights), axis=1) # N x 1\n",
    "    return sent_to_doc_class\n",
    "\n",
    "def docToClass(doc_repr, class_repr):\n",
    "    # doc_repr: N x E\n",
    "    # class_repr: C x E\n",
    "\n",
    "    #cos-sim between N x E and C x E = N x C\n",
    "    doccos = cosine_similarity(doc_repr, class_repr)\n",
    "    doc_to_class = np.argmax(doccos, axis=1) # N x 1\n",
    "    return doc_to_class\n",
    "\n",
    "def evaluate_predictions(true_class, predicted_class, output_to_console=True, return_tuple=False):\n",
    "    confusion = confusion_matrix(true_class, predicted_class)\n",
    "    if output_to_console:\n",
    "        print(\"-\" * 80 + \"Evaluating\" + \"-\" * 80)\n",
    "        print(confusion)\n",
    "    f1_macro = f1_score(true_class, predicted_class, average='macro')\n",
    "    f1_micro = f1_score(true_class, predicted_class, average='micro')\n",
    "    if output_to_console:\n",
    "        print(\"F1 macro: \" + str(f1_macro))\n",
    "        print(\"F1 micro: \" + str(f1_micro))\n",
    "    if return_tuple:\n",
    "        return confusion, f1_macro, f1_micro\n",
    "    else:\n",
    "        return {\n",
    "            \"confusion\": confusion.tolist(),\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_micro\": f1_micro\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEGClass Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGClassModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
    "        #super().__init__(config)\n",
    "        super(MEGClassModel, self).__init__()\n",
    "\n",
    "        self.attention  = torch.nn.MultiheadAttention(emb_dim, num_heads, batch_first=True)\n",
    "        # Two-layer MLP\n",
    "        self.ffn1 = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2*emb_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2*emb_dim, emb_dim)\n",
    "        )\n",
    "        self.ffn2 = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "        self.sent_attention = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "            )\n",
    "\n",
    "        self.scalar_sent_attention = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1, 1, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_emb, mask=None):\n",
    "        # input_emb: batch size x sequence length x emb_dim\n",
    "        X, _ = self.attention(input_emb, input_emb, input_emb, key_padding_mask=mask)\n",
    "        X = X + input_emb\n",
    "        X = self.ffn2(X)\n",
    "        contextualized_sent = self.norm1(X) #[~mask] N x S x E\n",
    "\n",
    "        # scalar attention weight for each sentence\n",
    "        exp_sent = torch.exp(self.scalar_sent_attention(contextualized_sent)) # N x S x 1\n",
    "        exp_sent = torch.squeeze(exp_sent, dim=2) * (~mask).int().float() # N x S x 1 but all masked items are 0\n",
    "        denom = torch.unsqueeze(torch.sum(exp_sent, dim=1), dim=1) # N x 1\n",
    "        alpha = torch.unsqueeze(torch.div(exp_sent, denom), dim=2) # N x S x 1\n",
    "        contextualized_doc = torch.sum(alpha.expand_as(contextualized_sent) * contextualized_sent, dim=1) # N x 1 x E\n",
    "\n",
    "        # convert mask from N x S to N x S x E\n",
    "        # full_mask = (~mask).unsqueeze(-1).expand(X.size())\n",
    "        # exp_sent = torch.exp(self.sent_attention(contextualized_sent)) # N x S x E\n",
    "        # denom = torch.unsqueeze(torch.sum(exp_sent * (full_mask).int().float(), dim=1), dim=1) # N x 1 x E\n",
    "        # contextualized_doc = torch.sum((torch.div(exp_sent, denom) * contextualized_sent) * (full_mask), dim=1) # N x 1 x E\n",
    "\n",
    "        return contextualized_sent, contextualized_doc, alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_repr, new_data_path, device):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    dataset = TensorDataset(sent_representations, mask)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 1024 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        model.zero_grad()\n",
    "        for j, batch in enumerate(tqdm(dataset_loader)):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            \n",
    "            c_sent, c_doc, _ = model(input_emb, mask=input_mask)\n",
    "\n",
    "            i_sim = findMaxClass(torch.from_numpy(class_repr).float().to(device), c_doc)\n",
    "\n",
    "            loss = contrastive_loss(torch.from_numpy(class_repr).float().to(device), c_doc, i_sim) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = torch.tensor([total_train_loss / len(dataset_loader) * args.accum_steps])\n",
    "        print(f\"Average training loss: {avg_train_loss.mean()}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_weights.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    sentence_predictions = None\n",
    "    doc_predictions = None\n",
    "\n",
    "    with torch.no_grad(), open(os.path.join(new_data_path, \"contextualized_sent.txt\"), 'w') as fs, open(os.path.join(new_data_path, \"contextualized_docs.txt\"), 'w') as fd:\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_sent, c_doc, alpha = model(input_emb, mask=input_mask)\n",
    "            c_sent = tensor_to_numpy(c_sent)\n",
    "            c_doc = tensor_to_numpy(c_doc)\n",
    "            alpha = tensor_to_numpy(torch.squeeze(alpha, dim=2))\n",
    "\n",
    "            # for row in c_doc:\n",
    "            #     fd.write(' '.join(map(str, row)) + '\\n')\n",
    "\n",
    "            # fs.write(str(c_sent))\n",
    "            # fs.write(\"\\n\")\n",
    "\n",
    "            # fd.write(str(c_doc))\n",
    "            # fd.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            sent_class = sentenceToClass(c_sent, class_repr, alpha)\n",
    "            doc_class = docToClass(c_doc, class_repr)\n",
    "            if sentence_predictions is None:\n",
    "                sentence_predictions = sent_class\n",
    "                doc_predictions = doc_class\n",
    "            else:\n",
    "                sentence_predictions = np.append(sentence_predictions, sent_class)\n",
    "                doc_predictions = np.append(doc_predictions, doc_class)\n",
    "\n",
    "    # return tensor_to_numpy(context_sent), tensor_to_numpy(context_doc), class_repr\n",
    "    return sentence_predictions, doc_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Contextualized Embedding Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:35<00:00, 19.73it/s]\n",
      " 20%|██        | 1/5 [01:35<06:20, 95.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.35764655470848083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:35<00:00, 19.64it/s]\n",
      " 40%|████      | 2/5 [03:10<04:46, 95.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.3715905249118805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:34<00:00, 19.77it/s]\n",
      " 60%|██████    | 3/5 [04:45<03:10, 95.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.4131544828414917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:35<00:00, 19.68it/s]\n",
      " 80%|████████  | 4/5 [06:20<01:35, 95.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.48218175768852234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:35<00:00, 19.53it/s]\n",
      "100%|██████████| 5/5 [07:57<00:00, 95.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: -0.5789074897766113\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [07:07<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_to_doc_class, doc_to_class = contextEmb(args, padded_sent_representations, sentence_mask, class_repr, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000,), (120000,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_doc_class.shape, doc_to_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_doc_class[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Sentence-Based): \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m doc_pred \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(np\u001b[39m.\u001b[39mrint(doc_to_class))\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluate Predictions (Sentence-Based): \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m evaluate_predictions(gold_labels, sent_pred)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluate Predictions (Document-Based): \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m evaluate_predictions(gold_labels, doc_pred)\n",
      "Cell \u001b[0;32mIn[14], line 74\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(true_class, predicted_class, output_to_console, return_tuple)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_predictions\u001b[39m(true_class, predicted_class, output_to_console\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tuple\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 74\u001b[0m     confusion \u001b[39m=\u001b[39m confusion_matrix(true_class, predicted_class)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m output_to_console:\n\u001b[1;32m     76\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEvaluating\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n",
      "File \u001b[0;32m~/MEGClass/megclass/lib/python3.8/site-packages/sklearn/metrics/_classification.py:322\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(labels)\n",
      "File \u001b[0;32m~/MEGClass/megclass/lib/python3.8/site-packages/sklearn/utils/multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39misinstance\u001b[39m(label, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m ys_labels)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMix of label input types (string and number)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(\u001b[39msorted\u001b[39m(ys_labels))\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"labels.txt\"), \"r\") as l:\n",
    "        gold_labels = l.read().splitlines()\n",
    "\n",
    "sent_pred = np.rint(sent_to_doc_class)\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "\n",
    "print(\"Evaluate Predictions (Sentence-Based): \")\n",
    "evaluate_predictions(gold_labels, sent_pred)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bc78f6dd8c9fb4bf4049d09abbebcbc9ae8bd98d8b55b5fea020bfdbf1269a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
