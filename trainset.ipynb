{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import re\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.decomposition import PCA\n",
    "from shutil import copyfile\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture._gaussian_mixture import _estimate_gaussian_parameters\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.dataset_name = \"books\"\n",
    "args.gpu = 1\n",
    "args.pca = 64\n",
    "args.random_state = 42\n",
    "args.emb_dim = 768\n",
    "args.num_heads = 2\n",
    "args.batch_size = 64\n",
    "args.temp = 0.2\n",
    "args.lr = 1e-3\n",
    "args.epochs = 4\n",
    "args.accum_steps = 1\n",
    "args.max_sent = 150\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name)\n",
    "new_data_path = os.path.join(\"/home/pk36/MEGClass/intermediate_data\", args.dataset_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this is where we save all representations\n",
    "if not os.path.exists(new_data_path):\n",
    "    os.makedirs(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = os.path.join(\"/shared/data2/pk36/multidim/multigran\")\n",
    "INTERMEDIATE_DATA_FOLDER_PATH = os.path.join(\"/home/pk36/MEGClass/intermediate_data\")\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.clone().detach().cpu().numpy()\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def sentenceToClass(sent_repr, class_repr, weights):\n",
    "    # sent_repr: N x S x E\n",
    "    # class_repr: C x E\n",
    "    # weights: N x S # equals 0 for masked sentences\n",
    "\n",
    "    #cos-sim between (N x S) x E and (C x E) = N x S x C\n",
    "    m, n = sent_repr.shape[:2]\n",
    "    sentcos = cosine_similarity(sent_repr.reshape(m*n,-1), class_repr).reshape(m,n,-1)\n",
    "    sent_to_class = np.argmax(sentcos, axis=2) # N x S\n",
    "    sent_to_doc_class = np.sum(np.multiply(sent_to_class, weights), axis=1) # N x 1\n",
    "    return sent_to_doc_class\n",
    "\n",
    "def docToClass(doc_repr, class_repr):\n",
    "    # doc_repr: N x E\n",
    "    # class_repr: C x E\n",
    "\n",
    "    #cos-sim between N x E and C x E = N x C\n",
    "    doccos = cosine_similarity(doc_repr, class_repr)\n",
    "    doc_to_class = np.argmax(doccos, axis=1) # N x 1\n",
    "    return doc_to_class\n",
    "\n",
    "def evaluate_predictions(true_class, predicted_class, output_to_console=True, return_tuple=False, return_confusion=False):\n",
    "    confusion = confusion_matrix(true_class, predicted_class)\n",
    "    if return_confusion and output_to_console:\n",
    "        print(\"-\" * 80 + \"Evaluating\" + \"-\" * 80)\n",
    "        print(confusion)\n",
    "    \n",
    "    f1_micro = f1_score(true_class, predicted_class, average='micro')\n",
    "    f1_macro = f1_score(true_class, predicted_class, average='macro')\n",
    "    if output_to_console:\n",
    "        print(\"F1 micro: \" + str(f1_micro))\n",
    "        print(\"F1 macro: \" + str(f1_macro))\n",
    "    if return_tuple:\n",
    "        return f1_macro, f1_micro\n",
    "    else:\n",
    "        return {\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro\n",
    "        }\n",
    "    \n",
    "def getSentClassRepr(args):\n",
    "    with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, f\"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "        dictionary = pk.load(f)\n",
    "        class_repr = dictionary[\"class_representations\"]\n",
    "        sent_repr = dictionary[\"sent_representations\"]\n",
    "        if (args.dataset_name in [\"nyt-location\", \"books\", \"nyt-fine-updated\", \"nyt-coarse-nophrase\"]):\n",
    "         return sent_repr, class_repr\n",
    "        else:\n",
    "            doc_repr = dictionary[\"document_representations\"]\n",
    "    return doc_repr, sent_repr, class_repr\n",
    "\n",
    "\n",
    "def getDSMapAndGold(args, sent_dict):\n",
    "    # get the ground truth labels for all documents and assign a \"ground truth\" label to each sentence based on its parent document\n",
    "    gold_labels = list(map(int, open(os.path.join(\"/shared/data2/pk36/multidim/multigran\", args.dataset_name, \"labels.txt\"), \"r\").read().splitlines()))\n",
    "    gold_sent_labels = []\n",
    "    # get all sent ids for each doc\n",
    "    doc_to_sent = []\n",
    "    sent_id = 0\n",
    "    for doc_id, doc in enumerate(sent_dict.values()):\n",
    "        sent_ids = []\n",
    "        for sent in doc:\n",
    "            sent_ids.append(sent_id)\n",
    "            gold_sent_labels.append(gold_labels[doc_id])\n",
    "            sent_id += 1\n",
    "        doc_to_sent.append(sent_ids)\n",
    "            \n",
    "    return gold_labels, gold_sent_labels, doc_to_sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-Based Sentence Embeddings, Initial Doc Embeddings, & Class Representations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceEmb(args, sent_dict, doc_to_sent, class_words, device, classonly=False):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    num_docs = len(doc_to_sent)\n",
    "    padded_sent_repr = np.zeros((num_docs, args.max_sent, args.emb_dim))\n",
    "    sentence_mask = np.ones((num_docs, args.max_sent))\n",
    "    doc_lengths = np.zeros(num_docs, dtype=int)\n",
    "    trimmed = 0\n",
    "\n",
    "    if not classonly:\n",
    "        for doc_id in tqdm(np.arange(num_docs)):\n",
    "            sents = sent_dict[str(doc_id)]\n",
    "            num_sent = len(sents)\n",
    "            if num_sent > args.max_sent:\n",
    "                trimmed += 1\n",
    "                sents = sents[:args.max_sent]\n",
    "                num_sent = args.max_sent\n",
    "            encoded_input = tokenizer(sents, padding=True, truncation=True, return_tensors='pt')\n",
    "            encoded_input = encoded_input.to(device)\n",
    "\n",
    "            # Compute token embeddings\n",
    "            with torch.no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "\n",
    "            # Perform pooling\n",
    "            embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "            # Normalize embeddings\n",
    "            embeddings = tensor_to_numpy(F.normalize(embeddings, p=2, dim=1))\n",
    "\n",
    "            # save the number of sentences in each document\n",
    "            doc_lengths[doc_id] = int(num_sent)\n",
    "\n",
    "            padded_sent_repr[doc_id, :embeddings.shape[0], :] = embeddings\n",
    "            # Update mask so that padded sentences are not included in attention computation\n",
    "            sentence_mask[doc_id, :num_sent] = 0\n",
    "        print(f\"Trimmed Documents: {trimmed}\")\n",
    "\n",
    "    # construct class representations\n",
    "    class_repr = np.zeros((len(class_words), args.emb_dim))\n",
    "    intro_map = {\"20News\":\"This article is about \", \"agnews\": \"This article is about \",\n",
    "                \"yelp\": \"This is \", \"nyt-coarse\":\"This article is about \", \n",
    "                \"nyt-fine\": \"This article is about \"}\n",
    "\n",
    "    print(\"Constructing Class Representations...\")\n",
    "    for class_id in tqdm(np.arange(len(class_words))):\n",
    "        # class_sent = intro_map[args.dataset_name] + \", \".join(class_words[class_id])\n",
    "        class_sent = intro_map[args.dataset_name] + class_words[class_id][0]\n",
    "        \n",
    "        print(class_sent)\n",
    "        encoded_input = tokenizer(class_sent, truncation=True, return_tensors='pt')\n",
    "        encoded_input = encoded_input.to(device)\n",
    "         # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        # Perform pooling\n",
    "        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        # Normalize embeddings\n",
    "        embeddings = tensor_to_numpy(F.normalize(embeddings, p=2, dim=1))\n",
    "        class_repr[class_id, :] = embeddings\n",
    "    \n",
    "    if classonly:\n",
    "        return class_repr\n",
    "    else:\n",
    "        return padded_sent_repr, class_repr, doc_lengths, sentence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertSentenceEmb(args, doc_to_sent, sent_repr):\n",
    "    num_docs = len(doc_to_sent)\n",
    "    doc_lengths = np.zeros(num_docs, dtype=int)\n",
    "    # init_doc_repr = np.zeros((num_docs, args.emb_dim))\n",
    "    padded_sent_repr = np.zeros((num_docs, args.max_sent, args.emb_dim))\n",
    "    sentence_mask = np.ones((num_docs, args.max_sent))\n",
    "    trimmed = 0\n",
    "\n",
    "\n",
    "    for doc_id in tqdm(np.arange(num_docs)):\n",
    "        start_sent = doc_to_sent[doc_id][0]\n",
    "        end_sent = doc_to_sent[doc_id][-1]\n",
    "        num_sent = end_sent - start_sent + 1\n",
    "        if num_sent > args.max_sent:\n",
    "            end_sent = start_sent + args.max_sent - 1\n",
    "            num_sent = args.max_sent\n",
    "            trimmed += 1\n",
    "        embeddings = sent_repr[start_sent:end_sent+1]\n",
    "\n",
    "        # save the number of sentences in each document\n",
    "        doc_lengths[doc_id] = int(num_sent)\n",
    "\n",
    "        # Add initial doc representation\n",
    "        # init_doc_repr[doc_id, :] = np.mean(embeddings, axis=0)\n",
    "        # Add padded sentences\n",
    "        padded_sent_repr[doc_id, :embeddings.shape[0], :] = embeddings\n",
    "        # Update mask so that padded sentences are not included in attention computation\n",
    "        sentence_mask[doc_id, :num_sent] = 0\n",
    "\n",
    "    \n",
    "    print(f\"Trimmed Documents: {trimmed}\")\n",
    "\n",
    "    return padded_sent_repr, doc_lengths, sentence_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class Weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetClasses(padded_sent_repr, doc_lengths, class_repr, weights=None):\n",
    "    # weights: N x 150\n",
    "    class_weights = np.zeros((padded_sent_repr.shape[0], class_repr.shape[0])) # N x C\n",
    "    sent_weights = np.zeros(padded_sent_repr.shape[:2])\n",
    "\n",
    "    for doc_id in tqdm(np.arange(padded_sent_repr.shape[0])):\n",
    "        l = doc_lengths[doc_id]\n",
    "        sent_emb = padded_sent_repr[doc_id, :l, :] # S x E\n",
    "        sentcos = cosine_similarity(sent_emb, class_repr) # S x C\n",
    "        sent_to_class = np.argmax(sentcos, axis=1) # S\n",
    "\n",
    "        # add sentence centrality to weight\n",
    "        # cent = np.zeros(l)\n",
    "        # sent_to_sent = cosine_similarity(sent_emb, sent_emb) # S x S\n",
    "        # sim = np.triu(sent_to_sent)\n",
    "        # np.fill_diagonal(sim, 0)\n",
    "        # sim = sim[:l-1, :]\n",
    "        # simsum = np.divide(sim.sum(axis=1), np.arange(l - 1, 0, -1)) # S x 1\n",
    "        # cent[:l-1] = simsum/(simsum.sum())\n",
    "        \n",
    "        # default: equal vote weight between all sentences\n",
    "        if weights is None:\n",
    "            # w = np.ones(doc_lengths[doc_id])/doc_lengths[doc_id]\n",
    "            # top cos-sim - second cos-sim\n",
    "            toptwo = np.partition(sentcos, -2)[:, -2:] # S x 2\n",
    "            toptwo = toptwo[:, 1] - toptwo[:, 0] # S\n",
    "            w = toptwo / np.sum(toptwo)\n",
    "            # w = (w + cent)/2\n",
    "            sent_weights[doc_id, :l] = w\n",
    "        else:\n",
    "            w = weights[doc_id, :l]\n",
    "        \n",
    "        class_weights[doc_id, :] = np.bincount(sent_to_class, weights=w, minlength=class_repr.shape[0])\n",
    "\n",
    "    if weights is None:\n",
    "        return class_weights, sent_weights\n",
    "    else:\n",
    "        return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetClassSet(padded_sent_repr, doc_lengths, class_set, alpha=None, set_weights=None):\n",
    "    # sent_weights: N x 150 -> weigh each sentence based on its contribution to the document\n",
    "    # set_weights: C x CD -> how confident each class-indicative document is\n",
    "\n",
    "    class_weights = np.zeros((padded_sent_repr.shape[0], len(class_set))) # N x C\n",
    "    if alpha is None:\n",
    "        sent_weights = np.zeros(padded_sent_repr.shape[:2]) # N x 150\n",
    "\n",
    "    for doc_id in tqdm(np.arange(padded_sent_repr.shape[0])):\n",
    "        l = doc_lengths[doc_id]\n",
    "        sent_emb = padded_sent_repr[doc_id, :l, :] # S x E\n",
    "        sentclass_dist = np.zeros((l, len(class_set))) # S x C\n",
    "\n",
    "        for class_id in np.arange(len(class_set)):\n",
    "            sentcos = cosine_similarity(sent_emb, class_set[class_id]) # S x CD\n",
    "            if set_weights is None:\n",
    "                sentclass_sim = np.mean(sentcos, axis=1) # on average, how similar each sentence is to the class set\n",
    "            else:\n",
    "                sentclass_sim = np.average(sentcos, axis=1, weights=set_weights[class_id]) # same but weighted average based on class-indicativeness\n",
    "            \n",
    "            sentclass_dist[:, class_id] = sentclass_sim\n",
    "\n",
    "\n",
    "        sent_to_class = np.argmax(sentclass_dist, axis=1) # S\n",
    "\n",
    "        # add sentence centrality to weight\n",
    "        # cent = np.zeros(l)\n",
    "        # sent_to_sent = cosine_similarity(sent_emb, sent_emb) # S x S\n",
    "        # sim = np.triu(sent_to_sent)\n",
    "        # np.fill_diagonal(sim, 0)\n",
    "        # sim = sim[:l-1, :]\n",
    "        # simsum = np.divide(sim.sum(axis=1), np.arange(l - 1, 0, -1)) # S x 1\n",
    "        # cent[:l-1] = simsum/(simsum.sum())\n",
    "        \n",
    "        # default: equal vote weight between all sentences\n",
    "        if alpha is None:\n",
    "            # top cos-sim - second cos-sim\n",
    "            toptwo = np.partition(sentclass_dist, -2)[:, -2:] # S x 2\n",
    "            toptwo = toptwo[:, 1] - toptwo[:, 0] # S\n",
    "            w = toptwo / np.sum(toptwo)\n",
    "            # w = (w + cent)/2\n",
    "            sent_weights[doc_id, :l] = w\n",
    "        else:\n",
    "            w = alpha[doc_id, :l]\n",
    "        \n",
    "        class_weights[doc_id, :] = np.bincount(sent_to_class, weights=w, minlength=len(class_set))\n",
    "        # class_weights[doc_id, :] = np.bincount(sent_to_class, minlength=len(class_set))\n",
    "\n",
    "    if alpha is None:\n",
    "        return class_weights, sent_weights\n",
    "    else:\n",
    "        return class_weights\n",
    "    \n",
    "def docToClassSet(doc_emb, class_set, set_weights=None):\n",
    "    # set_weights: C x CD -> how confident each class-indicative document is\n",
    "\n",
    "    class_dist = np.zeros((doc_emb.shape[0], len(class_set))) # D x C\n",
    "    for class_id in np.arange(len(class_set)):\n",
    "        doccos = cosine_similarity(doc_emb, class_set[class_id]) # D x CD\n",
    "        if set_weights is None:\n",
    "            cos_sim = np.mean(doccos, axis=1) # on average, how similar each document is to the class set\n",
    "        else:\n",
    "            cos_sim = np.average(doccos, axis=1, weights=set_weights[class_id]) # same but weighted average based on class-indicativeness\n",
    "        \n",
    "        class_dist[:, class_id] = cos_sim\n",
    "    \n",
    "    return np.argmax(class_dist, axis=1), class_dist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial embeddings and class representations + gold labels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"dataset.pk\"), \"rb\") as f:\n",
    "    dataset = pk.load(f)\n",
    "    sent_dict = dataset[\"sent_data\"]\n",
    "    cleaned_text = dataset[\"cleaned_text\"]\n",
    "    class_names = np.array(dataset[\"class_names\"])\n",
    "with open(os.path.join(\"/home/pk36/XClass/data/intermediate_data\", args.dataset_name, \"document_repr_lm-bbu-12-mixture-plm.pk\"), \"rb\") as f:\n",
    "    reprpickle = pk.load(f)\n",
    "    class_words = reprpickle[\"class_words\"]\n",
    "gold_labels, gold_sent_labels, doc_to_sent = getDSMapAndGold(args, sent_dict)\n",
    "num_classes = len(class_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Representations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_repr, class_repr = getSentClassRepr(args)\n",
    "init_class_set = [np.array([class_repr[i]]) for i in np.arange(len(class_repr))] # C x CD x E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33594/33594 [00:00<00:00, 49067.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33594/33594 [01:02<00:00, 536.08it/s]\n"
     ]
    }
   ],
   "source": [
    "class_set = [np.array([class_repr[i]]) for i in np.arange(len(class_repr))] # C x CD x E\n",
    "\n",
    "padded_sent_repr, doc_lengths, sentence_mask = bertSentenceEmb(args, doc_to_sent, sent_repr)\n",
    "init_class_weights, init_sent_weights = getTargetClassSet(padded_sent_repr, doc_lengths, class_set, alpha=None, set_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-Oriented:\n",
      "F1 micro: 0.5027981187116747\n",
      "F1 macro: 0.5051026475634897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.5027981187116747, 'f1_macro': 0.5051026475634897}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Class-Oriented:\")\n",
    "evaluate_predictions(gold_labels, np.argmax(init_class_weights, axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Class Imbalance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health', 'medical', 'healthcare', 'medicine', 'hospital', 'physician', 'care', 'hospitalization', 'medically', 'physicians', 'hospitals', 'doctor', 'clinical', 'nonmedical', 'surgeon', 'doctors', 'hospitalizations', 'cardiologists', 'obstetrician', 'radiology', 'cardiologist', 'pathologist', 'patient', 'pediatrician', 'pediatricians', 'obstetricians', 'neurologists', 'pathologists', 'clinicians', 'anesthesiologists', 'cardiology', 'medics', 'medic', 'radiologists', 'neurosurgery', 'anesthesiologist', 'gynecologist', 'neurologist', 'radiologist', 'paramedic', 'oncologist', 'neurosurgeon', 'immunologist', 'pharmacist', 'neurosurgeons', 'gynecologists', 'urologist', 'gastroenterologist', 'surgical', 'obstetric', 'obstetrics', 'pediatrics', 'biomedical', 'neurology', 'obstetrical', 'inpatient', 'outpatient', 'orthopedic', 'sanitarium', 'nurse', 'epidemiologists', 'gynecological', 'epidemiologist', 'ophthalmologist', 'diabetics', 'pharmacists', 'dermatology', 'diagnostic', 'dialysis', 'outpatients', 'clinically', 'cardiological', 'homeopathy', 'orthopedics', 'surgery', 'patients', 'surgeries', 'paramedics', 'dermatologist', 'thoracic', 'dermatologists', 'ambulatory', 'orthopedist', 'endocrinology', 'gynecology', 'inpatients', 'homeopathic', 'practitioner', 'mammogram', 'epidemiology', 'psychotherapists', 'prognosis', 'urology', 'postoperative', 'biopsy', 'treatment', 'immunizations', 'psychotherapist', 'physiologist']\n"
     ]
    }
   ],
   "source": [
    "print(class_words[list(class_names).index(\"health\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business (Init Total: 10891.0, 0.3404, [ 651. 9018. 1873.], 0.3022):\n",
      "Precision: 0.932671424139001, Recall: 0.8280231383711322\n",
      "business (Curr Total: 10891.0, 0.3404, [ 477. 9158. 1733.], 0.3011):\n",
      "Precision: 0.950492994291645, Recall: 0.8408777890000918\n",
      "\n",
      "\n",
      "politics (Init Total: 10221.0, 0.3194, [3791. 9216. 1005.], 0.4065):\n",
      "Precision: 0.7085415545475513, Recall: 0.9016730261226886\n",
      "politics (Curr Total: 10221.0, 0.3194, [2827. 8862. 1359.], 0.3653):\n",
      "Precision: 0.7581486867995552, Recall: 0.8670384502494863\n",
      "\n",
      "\n",
      "sports (Init Total: 2943.0, 0.092, [ 131. 2562.  381.], 0.0842):\n",
      "Precision: 0.9513553657630895, Recall: 0.8705402650356778\n",
      "sports (Curr Total: 2943.0, 0.092, [ 364. 2664.  279.], 0.0946):\n",
      "Precision: 0.8797886393659181, Recall: 0.9051987767584098\n",
      "\n",
      "\n",
      "health (Init Total: 2383.0, 0.0745, [ 435. 1170. 1213.], 0.0502):\n",
      "Precision: 0.7289719626168224, Recall: 0.49097775912715064\n",
      "health (Curr Total: 2383.0, 0.0745, [ 392. 1400.  983.], 0.056):\n",
      "Precision: 0.78125, Recall: 0.5874947545111204\n",
      "\n",
      "\n",
      "education (Init Total: 1783.0, 0.0557, [ 210. 1367.  416.], 0.0493):\n",
      "Precision: 0.8668357641090678, Recall: 0.7666853617498598\n",
      "education (Curr Total: 1783.0, 0.0557, [ 256. 1474.  309.], 0.0541):\n",
      "Precision: 0.8520231213872832, Recall: 0.8266965787997756\n",
      "\n",
      "\n",
      "estate (Init Total: 1648.0, 0.0515, [ 375. 1416.  232.], 0.056):\n",
      "Precision: 0.7906197654941374, Recall: 0.8592233009708737\n",
      "estate (Curr Total: 1648.0, 0.0515, [ 542. 1480.  168.], 0.0632):\n",
      "Precision: 0.731948565776459, Recall: 0.8980582524271845\n",
      "\n",
      "\n",
      "arts (Init Total: 1214.0, 0.0379, [ 61. 631. 583.], 0.0216):\n",
      "Precision: 0.911849710982659, Recall: 0.5197693574958814\n",
      "arts (Curr Total: 1214.0, 0.0379, [ 85. 747. 467.], 0.026):\n",
      "Precision: 0.8978365384615384, Recall: 0.6153212520593081\n",
      "\n",
      "\n",
      "science (Init Total: 512.0, 0.016, [160.  66. 446.], 0.0071):\n",
      "Precision: 0.2920353982300885, Recall: 0.12890625\n",
      "science (Curr Total: 512.0, 0.016, [160.  52. 460.], 0.0066):\n",
      "Precision: 0.24528301886792453, Recall: 0.1015625\n",
      "\n",
      "\n",
      "technology (Init Total: 402.0, 0.0126, [632. 105. 297.], 0.023):\n",
      "Precision: 0.14246947082767977, Recall: 0.26119402985074625\n",
      "technology (Curr Total: 402.0, 0.0126, [921. 136. 266.], 0.033):\n",
      "Precision: 0.12866603595080417, Recall: 0.3383084577114428\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_doc_preds = np.argmax(init_class_weights, axis=1)\n",
    "curr_doc_preds = np.argmax(curr_class_weights, axis=1)\n",
    "\n",
    "def computeConfusion(preds):\n",
    "    class_imb = np.zeros((num_classes, 3)) # count FP, TP, FN\n",
    "    miscls = np.zeros((num_classes, num_classes))\n",
    "\n",
    "    for i in np.arange(len(gold_labels)):\n",
    "        if gold_labels[i] == preds[i]:\n",
    "            class_imb[gold_labels[i]][1] += 1\n",
    "        else:\n",
    "            class_imb[gold_labels[i]][2] += 1\n",
    "            class_imb[preds[i]][0] += 1\n",
    "            \n",
    "        miscls[gold_labels[i]][preds[i]] += 1\n",
    "\n",
    "    return class_imb, miscls\n",
    "\n",
    "init_class_imb, init_miscls = computeConfusion(init_doc_preds)\n",
    "curr_class_imb, curr_miscls = computeConfusion(curr_doc_preds)\n",
    "\n",
    "for i in np.arange(num_classes):\n",
    "    gold_prop = np.sum(gold_labels == i)/len(gold_labels)\n",
    "    init_prop = np.sum(init_doc_preds == i)/len(init_doc_preds)\n",
    "    curr_prop = np.sum(curr_doc_preds == i)/len(curr_doc_preds)\n",
    "    # Precision: out of all of the docs labeled abortion, which ones were correct?\n",
    "    # Recall: out of all of the true abortion docs, how many were correctly identified?\n",
    "    print(f'{class_names[i]} (Init Total: {init_class_imb[i][1] + init_class_imb[i][2]}, {round(gold_prop,4)}, {init_class_imb[i]}, {round(init_prop, 4)}):')\n",
    "    print(f'Precision: {init_class_imb[i][1]/(init_class_imb[i][0] + init_class_imb[i][1])}, Recall: {init_class_imb[i][1]/(init_class_imb[i][1] + init_class_imb[i][2])}')\n",
    "    print(f'{class_names[i]} (Curr Total: {curr_class_imb[i][1] + curr_class_imb[i][2]}, {round(gold_prop,4)}, {curr_class_imb[i]}, {round(curr_prop, 4)}):')\n",
    "    print(f'Precision: {curr_class_imb[i][1]/(curr_class_imb[i][0] + curr_class_imb[i][1])}, Recall: {curr_class_imb[i][1]/(curr_class_imb[i][1] + curr_class_imb[i][2])}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the most common misclassifications for each class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial business:\n",
      "business: 9018.0 politics: 1459.0 sports: 30.0 health: 21.0 education: 21.0 estate: 161.0 arts: 7.0 science: 11.0 technology: 163.0 \n",
      "Current business:\n",
      "business: 9158.0 politics: 1206.0 sports: 60.0 health: 20.0 education: 22.0 estate: 190.0 arts: 16.0 science: 13.0 technology: 206.0 \n",
      "\n",
      "Initial politics:\n",
      "business: 221.0 politics: 9216.0 sports: 53.0 health: 361.0 education: 35.0 estate: 35.0 arts: 10.0 science: 19.0 technology: 271.0 \n",
      "Current politics:\n",
      "business: 200.0 politics: 8862.0 sports: 266.0 health: 298.0 education: 65.0 estate: 78.0 arts: 14.0 science: 10.0 technology: 428.0 \n",
      "\n",
      "Initial sports:\n",
      "business: 49.0 politics: 258.0 sports: 2562.0 health: 16.0 education: 22.0 estate: 31.0 arts: 4.0 technology: 1.0 \n",
      "Current sports:\n",
      "business: 29.0 politics: 155.0 sports: 2664.0 health: 17.0 education: 28.0 estate: 36.0 arts: 8.0 technology: 6.0 \n",
      "\n",
      "Initial health:\n",
      "business: 117.0 politics: 841.0 sports: 13.0 health: 1170.0 education: 60.0 estate: 51.0 arts: 8.0 science: 114.0 technology: 9.0 \n",
      "Current health:\n",
      "business: 70.0 politics: 614.0 sports: 10.0 health: 1400.0 education: 70.0 estate: 68.0 arts: 6.0 science: 131.0 technology: 14.0 \n",
      "\n",
      "Initial education:\n",
      "business: 22.0 politics: 357.0 sports: 5.0 health: 6.0 education: 1367.0 estate: 14.0 arts: 5.0 science: 4.0 technology: 3.0 \n",
      "Current education:\n",
      "business: 13.0 politics: 250.0 sports: 4.0 health: 10.0 education: 1474.0 estate: 20.0 arts: 6.0 science: 1.0 technology: 5.0 \n",
      "\n",
      "Initial estate:\n",
      "business: 66.0 politics: 108.0 sports: 1.0 health: 6.0 education: 24.0 estate: 1416.0 arts: 21.0 technology: 6.0 \n",
      "Current estate:\n",
      "business: 45.0 politics: 67.0 health: 9.0 education: 23.0 estate: 1480.0 arts: 17.0 technology: 7.0 \n",
      "\n",
      "Initial arts:\n",
      "business: 56.0 politics: 398.0 sports: 23.0 health: 4.0 education: 31.0 estate: 38.0 arts: 631.0 science: 8.0 technology: 25.0 \n",
      "Current arts:\n",
      "business: 35.0 politics: 261.0 sports: 20.0 health: 7.0 education: 27.0 estate: 80.0 arts: 747.0 science: 3.0 technology: 34.0 \n",
      "\n",
      "Initial science:\n",
      "business: 44.0 politics: 187.0 sports: 1.0 health: 19.0 education: 8.0 estate: 32.0 arts: 1.0 science: 66.0 technology: 154.0 \n",
      "Current science:\n",
      "business: 17.0 politics: 126.0 sports: 2.0 health: 28.0 education: 8.0 estate: 55.0 arts: 3.0 science: 52.0 technology: 221.0 \n",
      "\n",
      "Initial technology:\n",
      "business: 76.0 politics: 183.0 sports: 5.0 health: 2.0 education: 9.0 estate: 13.0 arts: 5.0 science: 4.0 technology: 105.0 \n",
      "Current technology:\n",
      "business: 68.0 politics: 148.0 sports: 2.0 health: 3.0 education: 13.0 estate: 15.0 arts: 15.0 science: 2.0 technology: 136.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(num_classes):\n",
    "    print(f'Initial {class_names[i]}:')\n",
    "    for c in np.arange(num_classes):\n",
    "        if init_miscls[i][c] > 0:\n",
    "            print(f'{class_names[c]}: {init_miscls[i][c]}', end=\" \")\n",
    "    print(f'\\nCurrent {class_names[i]}:')\n",
    "    for c in np.arange(num_classes):\n",
    "        if curr_miscls[i][c] > 0:\n",
    "            print(f'{class_names[c]}: {curr_miscls[i][c]}', end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business: (10891 docs), 0.34037566021814547\n",
      "politics: (10221 docs), 0.3194361971434822\n",
      "sports: (2943 docs), 0.09197737287870737\n",
      "health: (2383 docs), 0.07447573209988437\n",
      "education: (1783 docs), 0.05572397412257399\n",
      "estate: (1648 docs), 0.05150482857767916\n",
      "arts: (1214 docs), 0.03794105697409132\n",
      "science: (512 docs), 0.016001500140638183\n",
      "technology: (402 docs), 0.01256367784479795\n",
      "Minority Classes:\n",
      "['sports', 'health', 'education', 'estate', 'arts', 'science', 'technology']\n"
     ]
    }
   ],
   "source": [
    "minority_cls = []\n",
    "for i in np.arange(num_classes):\n",
    "    prop = np.sum(gold_labels == i)/len(gold_labels)\n",
    "    print(f'{class_names[i]}: ({np.sum(gold_labels == i)} docs), {prop}')\n",
    "    if prop < (1/num_classes):\n",
    "        minority_cls.append(i)\n",
    "print(\"Minority Classes:\")\n",
    "print([class_names[c] for c in minority_cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34037566, 0.3194362 , 0.09197737, 0.07447573, 0.05572397,\n",
       "       0.05150483, 0.03794106, 0.0160015 , 0.01256368])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size = np.array([np.sum(gold_labels == i)/len(gold_labels) for i in np.arange(len(class_names))])\n",
    "class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04338665, 0.04594275, 0.09606501, 0.10456231, 0.11623976,\n",
       "       0.1194095 , 0.13171414, 0.16647125, 0.17620864])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(class_size)/np.sum(np.log(class_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31997/31997 [19:43<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Documents: 155\n",
      "Constructing Class Representations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 132.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is about business\n",
      "This article is about politics\n",
      "This article is about sports\n",
      "This article is about health\n",
      "This article is about education\n",
      "This article is about estate\n",
      "This article is about arts\n",
      "This article is about science\n",
      "This article is about technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31997/31997 [01:39<00:00, 320.20it/s]\n"
     ]
    }
   ],
   "source": [
    "plm_padded_sent_repr, plm_class_repr, doc_lengths, plm_sentence_mask = sentenceEmb(args, sent_dict, doc_to_sent, class_words, device)\n",
    "\n",
    "init_plm_class_set = [np.array([plm_class_repr[i]]) for i in np.arange(len(plm_class_repr))] # C x CD x E\n",
    "plm_class_set = [np.array([plm_class_repr[i]]) for i in np.arange(len(plm_class_repr))] # C x CD x E\n",
    "\n",
    "init_plm_class_weights, init_plm_sent_weights = getTargetClassSet(plm_padded_sent_repr, doc_lengths, init_plm_class_set, alpha=None, set_weights=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGClassModel(nn.Module):\n",
    "    def __init__(self, D_in, D_hidden, head, dropout=0.0):\n",
    "        super(MEGClassModel, self).__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=D_in, num_heads=head, dropout=dropout, batch_first=True)\n",
    "        self.layernorm = nn.LayerNorm(D_in)\n",
    "        self.embd = nn.Linear(D_in,D_hidden)\n",
    "        self.attention = nn.Linear(D_hidden,1)\n",
    "        \n",
    "    def forward(self, x_org, mask=None):\n",
    "        x, mha_w = self.mha(x_org,x_org,x_org,key_padding_mask=mask)\n",
    "        x = self.layernorm(x_org+x)\n",
    "        \n",
    "        x = self.embd(x)\n",
    "        x = torch.tanh(x) # contextualized sentences\n",
    "        a = self.attention(x)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill_((mask == 1).unsqueeze(-1), float('-inf'))\n",
    "        w = torch.softmax(a, dim=1) # alpha_k\n",
    "        o = torch.matmul(w.permute(0,2,1), x) #doc \n",
    "        return o, mha_w, w, x # contextualized doc, multi-head attention weights, alpha_k, contextualized sent\n",
    "    \n",
    "    def new_forward(self, x_org, classes=None, mask=None):\n",
    "        x, mha_w = self.mha(x_org,x_org,x_org,key_padding_mask=mask)\n",
    "        x = self.layernorm(x_org+x)\n",
    "        \n",
    "        x = self.embd(x)\n",
    "        x = torch.tanh(x) # contextualized sentences b x s x emb-dim\n",
    "        a = self.attention(x) # b x s x 1\n",
    "\n",
    "        cent = torch.zeros_like(a)\n",
    "        disc = torch.zeros_like(a)\n",
    "        for i in torch.arange(a.size(dim=0)):\n",
    "            # sentence centrality\n",
    "            if 1 in mask[i]:\n",
    "                numsent = torch.argmax(mask[i].to(torch.long))\n",
    "            else:\n",
    "                numsent = mask[i].size(dim=0)\n",
    "            xi_norm = x[i] / x[i].norm(dim=1)[:, None]\n",
    "            sim = torch.mm(xi_norm[:numsent], xi_norm[:numsent].transpose(0,1)) # s x s\n",
    "            sim = torch.triu(sim).fill_diagonal_(0)\n",
    "            sim = sim[:numsent-1] # numsent-1 x numsent\n",
    "            simsum = sim.sum(dim=1) # (numsent - 1) x 1\n",
    "            simlen = torch.arange(numsent - 1, 0, -1).to(device)\n",
    "            cent[i, :numsent-1] = nn.functional.normalize(torch.div(simsum, simlen).unsqueeze(-1), dim=0)\n",
    "\n",
    "            # sentence class contrastive\n",
    "            if classes is not None:\n",
    "                classnorm = classes / classes.norm(dim=1)[:,  None]\n",
    "                class_sim = torch.mm(xi_norm[:numsent], classnorm.transpose(0,1)) # s x c\n",
    "                toptwo = torch.topk(class_sim, 2, dim=1).values # S x 2\n",
    "                toptwo = torch.sub(toptwo[:, 0], toptwo[:, 1]) # s\n",
    "                disc[i, :numsent] = torch.div(toptwo, torch.sum(toptwo)).unsqueeze(-1)\n",
    "\n",
    "        # print(cent[5].flatten())\n",
    "        # print(disc[5].flatten())\n",
    "        # print(a[5].flatten())\n",
    "        # 1/0\n",
    "        a = torch.add(a, cent)\n",
    "        a = torch.add(a, disc)\n",
    "\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill_((mask == 1).unsqueeze(-1), float('-inf'))\n",
    "        w = torch.softmax(a, dim=1) # alpha_k\n",
    "        o = torch.matmul(w.permute(0,2,1), x) #doc \n",
    "        return o, mha_w, w, x # contextualized doc, multi-head attention weights, alpha_k, contextualized sent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(sample_outputs, class_indices, class_embds, temp=0.2):\n",
    "    k = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/temp)\n",
    "    loss = -1*(torch.log(k[np.arange(len(class_indices)),class_indices]/k.sum(1))).sum()\n",
    "    return loss/len(sample_outputs)\n",
    "\n",
    "def weighted_class_contrastive_loss(args, sample_outputs, class_weights, class_embds):\n",
    "    # k: B x C, class_weights: B x C\n",
    "    numerator = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    denom = numerator.sum(dim=1).unsqueeze(-1)\n",
    "    weighted_loss = -1 * (torch.log(numerator/(denom)) * class_weights).sum() # B x C -> B\n",
    "    return weighted_loss/len(sample_outputs)\n",
    "\n",
    "def weighted_contrastive_doc_sent_loss(args, sample_outputs, sent_output, sent_weights, sent_mask, class_weights, class_embds):\n",
    "    # k: B x C, class_weights: B x C\n",
    "    # weighted loss for each document repr and class repr\n",
    "\n",
    "    numerator = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:,None], class_embds, axis=2)/args.temp)\n",
    "    denom = numerator.sum(dim=1).unsqueeze(-1)\n",
    "    weighted_loss = -1 * (torch.log(numerator/(denom)) * class_weights).sum() # B x C -> B\n",
    "\n",
    "    return weighted_loss/len(sample_outputs)\n",
    "\n",
    "\n",
    "def classSetContrastiveLoss(args, sample_outputs, class_weights, class_set, device, set_weights=None):\n",
    "    # sample_outputs: B x E, class_weights: B x C, class_set: C x CD x E, set_weights: C x CD\n",
    "    # flatten_class_set = np.array([class_set[i][j] for i in np.arange(len(class_set)) for j in np.arange(len(class_set[i]))])\n",
    "    # flatten_class_set = torch.cat(class_set, dim=0)\n",
    "    # denom = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:, None], flatten_class_set, dim=2)/args.temp) # B x (C*CD)\n",
    "    # if set_weights is None:\n",
    "    #     denom = torch.sum(denom, dim=1).unsqueeze(-1) # B\n",
    "    # else:\n",
    "    #     denom = torch.sum(denom * set_weights.reshape(-1,), dim=1).unsqueeze(-1) # B\n",
    "    weighted_loss = torch.zeros((sample_outputs.size(dim=0), len(class_set))).to(device) # B x C\n",
    "    for i in np.arange(len(class_set)):\n",
    "        # similarity between contextualized docs and class-indicative docs\n",
    "        numerator = torch.exp(torch.nn.functional.cosine_similarity(sample_outputs[:, None], class_set[i], dim=2)/args.temp) # B x CD\n",
    "        weighted_loss[:, i] = numerator.mean(dim=1) # B x 1\n",
    "        # if set_weights is None:\n",
    "        #     numerator = torch.sum(numerator, dim=1) # B\n",
    "        # else:\n",
    "        #     numerator = torch.sum(torch.mul(numerator, set_weights[i]), dim=1) # B\n",
    "        # if set_weights is None:\n",
    "        \n",
    "    return -1 * (torch.log(weighted_loss/weighted_loss.sum(dim=1).unsqueeze(-1)) * class_weights).sum() / len(sample_outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_repr, class_weights, \n",
    "                doc_lengths, new_data_path, device):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask).to(torch.bool)\n",
    "    class_weights = torch.from_numpy(class_weights)\n",
    "    classes = torch.from_numpy(class_repr).float().to(device)\n",
    "    dataset = TensorDataset(sent_representations, mask, class_weights)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 768 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            model.train()\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            input_weights = batch[2].to(device).float()\n",
    "            \n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "\n",
    "            loss = weighted_class_contrastive_loss(args, c_doc, input_weights, classes) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(dataset_loader)\n",
    "        print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_e{args.epochs}.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    evalsampler = SequentialSampler(dataset)\n",
    "    eval_loader = DataLoader(dataset, sampler=evalsampler, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    doc_predictions = None\n",
    "    attention_weights = np.zeros_like(mask, dtype=float)\n",
    "    updated_sent_repr = np.zeros_like(sent_representations)\n",
    "    final_doc_emb = np.zeros((len(class_weights), args.emb_dim))\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "            c_sent, c_doc, alpha = tensor_to_numpy(c_sent), tensor_to_numpy(c_doc), tensor_to_numpy(torch.squeeze(alpha, dim=2))\n",
    "\n",
    "            final_doc_emb[idx:idx+c_doc.shape[0], :] = c_doc\n",
    "            attention_weights[idx:idx+c_doc.shape[0], :] = alpha\n",
    "            updated_sent_repr[idx:idx+c_doc.shape[0], :, :] = c_sent\n",
    "\n",
    "            idx += c_doc.shape[0]\n",
    "\n",
    "            doc_class = docToClass(c_doc, class_repr)\n",
    "            if doc_predictions is None:\n",
    "                doc_predictions = doc_class\n",
    "            else:\n",
    "                doc_predictions = np.append(doc_predictions, doc_class)\n",
    "    \n",
    "    updated_class_weights = getTargetClasses(updated_sent_repr, doc_lengths, class_repr, attention_weights)\n",
    "\n",
    "    return doc_predictions, final_doc_emb, updated_sent_repr, attention_weights, updated_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextEmb(args, sent_representations, mask, class_set, class_weights, \n",
    "                doc_lengths, new_data_path, device):\n",
    "    sent_representations = torch.from_numpy(sent_representations)\n",
    "    mask = torch.from_numpy(mask).to(torch.bool)\n",
    "    class_weights = torch.from_numpy(class_weights)\n",
    "    dataset = TensorDataset(sent_representations, mask, class_weights)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataset_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size, shuffle=False)\n",
    "    # sent_representations: N docs x L sentences x 768 emb (L with padding is always max_sents=50)\n",
    "    model = MEGClassModel(args.emb_dim, args.emb_dim, args.num_heads).to(device)\n",
    "\n",
    "    total_steps = len(dataset_loader) * args.epochs / args.accum_steps\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "    print(\"Starting to train!\")\n",
    "\n",
    "    for i in tqdm(range(args.epochs)):\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataset_loader):\n",
    "            model.train()\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "            input_weights = batch[2].to(device).float()\n",
    "            \n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "            torch_class_set = [torch.from_numpy(class_set[i]).float().to(device) for i in np.arange(len(class_set))]\n",
    "            loss = classSetContrastiveLoss(args, c_doc, input_weights, torch_class_set, device)/ args.accum_steps\n",
    "            # loss = weighted_class_contrastive_loss(args, c_doc, input_weights, torch.from_numpy(class_repr).float().to(device)) / args.accum_steps\n",
    "\n",
    "            total_train_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(dataset_loader)\n",
    "        print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(new_data_path, f\"{args.dataset_name}_model_e{args.epochs}.pth\"))\n",
    "\n",
    "    print(\"Starting to evaluate!\")\n",
    "\n",
    "    evalsampler = SequentialSampler(dataset)\n",
    "    eval_loader = DataLoader(dataset, sampler=evalsampler, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    doc_predictions = None\n",
    "    attention_weights = np.zeros_like(mask, dtype=float)\n",
    "    updated_sent_repr = np.zeros_like(sent_representations)\n",
    "    final_doc_emb = np.zeros((len(class_weights), args.emb_dim))\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            input_emb = batch[0].to(device).float()\n",
    "            input_mask = batch[1].to(device)\n",
    "\n",
    "            c_doc, _, alpha, c_sent = model(input_emb, mask=input_mask)\n",
    "            c_doc = c_doc.squeeze(1)\n",
    "            c_sent, c_doc, alpha = tensor_to_numpy(c_sent), tensor_to_numpy(c_doc), tensor_to_numpy(torch.squeeze(alpha, dim=2))\n",
    "\n",
    "            final_doc_emb[idx:idx+c_doc.shape[0], :] = c_doc\n",
    "            attention_weights[idx:idx+c_doc.shape[0], :] = alpha\n",
    "            updated_sent_repr[idx:idx+c_doc.shape[0], :, :] = c_sent\n",
    "\n",
    "            idx += c_doc.shape[0]\n",
    "\n",
    "            doc_class, _ = docToClassSet(c_doc, class_set)\n",
    "            if doc_predictions is None:\n",
    "                doc_predictions = doc_class\n",
    "            else:\n",
    "                doc_predictions = np.append(doc_predictions, doc_class)\n",
    "    \n",
    "    updated_class_weights = getTargetClassSet(updated_sent_repr, doc_lengths, class_set, attention_weights)\n",
    "\n",
    "    return doc_predictions, final_doc_emb, updated_sent_repr, attention_weights, updated_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:17<00:00, 29.19it/s]\n",
      " 25%|██▌       | 1/4 [00:17<00:53, 17.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.0641584396362305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:15<00:00, 33.59it/s]\n",
      " 50%|█████     | 2/4 [00:33<00:33, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.7929142713546753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:14<00:00, 35.20it/s]\n",
      " 75%|███████▌  | 3/4 [00:48<00:15, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.3813471794128418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:15<00:00, 34.00it/s]\n",
      "100%|██████████| 4/4 [01:04<00:00, 16.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.1902844905853271\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:20<00:00, 25.78it/s]\n",
      "100%|██████████| 33594/33594 [00:08<00:00, 3886.51it/s]\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 4 # NYT-Fine IS 5\n",
    "args.lr = 1e-3\n",
    "args.temp = 0.1\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, init_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.5150026790498303\n",
      "F1 macro: 0.518173483949235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.5150026790498303, 'f1_macro': 0.518173483949235}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 4\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Iteration ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33594/33594 [13:01<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro: 0.5281300232184318\n",
      "F1 macro: 0.5258843552347254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.5281300232184318, 'f1_macro': 0.5258843552347254}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_class_weights = getTargetClassSet(updated_sent_repr, doc_lengths, class_set, alpha=updated_sent_weights, set_weights=None)\n",
    "evaluate_predictions(gold_labels, np.argmax(curr_class_weights, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/MEGClass/megclass/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 37.56it/s]\n",
      " 25%|██▌       | 1/4 [00:07<00:22,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.624432921409607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 35.93it/s]\n",
      " 50%|█████     | 2/4 [00:15<00:15,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.3301043510437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 35.44it/s]\n",
      " 75%|███████▌  | 3/4 [00:23<00:07,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7405486106872559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 36.34it/s]\n",
      "100%|██████████| 4/4 [00:30<00:00,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.4643602669239044\n",
      "Starting to evaluate!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:10<00:00, 27.59it/s]\n",
      "100%|██████████| 17871/17871 [00:06<00:00, 2844.55it/s]\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 4\n",
    "args.lr = 1e-3\n",
    "args.temp = 0.1\n",
    "doc_to_class, final_doc_emb, updated_sent_repr, updated_sent_weights, updated_class_weights = contextEmb(args, padded_sent_repr, sentence_mask, class_repr, curr_class_weights, doc_lengths, new_data_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7865256560908733\n",
      "F1 macro: 0.7732321095083541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.7865256560908733, 'f1_macro': 0.7732321095083541}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 4; FOURTH ITER (USING INITIAL REPRESENTATIONS)\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7814895640982596\n",
      "F1 macro: 0.7692942005311851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.7814895640982596, 'f1_macro': 0.7692942005311851}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 4; THIRD ITER (USING INITIAL REPRESENTATIONS)\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Predictions (Document-Based): \n",
      "F1 micro: 0.7736556432208607\n",
      "F1 macro: 0.7602823259977058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.7736556432208607, 'f1_macro': 0.7602823259977058}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 4 SECOND ITER (USING INITIAL REPRESENTATIONS)\n",
    "doc_pred = np.rint(doc_to_class)\n",
    "print(\"Evaluate Predictions (Document-Based): \")\n",
    "evaluate_predictions(gold_labels, doc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClasses(x):\n",
    "    for i in np.arange(num_classes):\n",
    "        if x[i] > 0:\n",
    "            print(f'{class_names[i]}: {x[i]}', end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial CO Class Weights:\n",
      "computer: 0.6559191414637636 sports: 0.09092395911607942 politics: 0.25315689942015696 Updated Class Weights:\n",
      "computer: 0.8252974152565002 politics: 0.17470255494117737 True Class:  science\n",
      "computer ([ 0.22602685  0.04150834  0.0242996  -0.06390868 -0.11698047]) 0.2958510220050812: re lyme vaccine nntp-posting-host ucrengr x-newsreader tin version 1.1 pl8 jeff, if you have time to type it in i'd love to have the reference for that paper!\n",
      "computer ([ 0.03197761 -0.06128826 -0.04751204 -0.04008535 -0.12241898]) 0.20030459761619568: thanks!\n",
      "computer ([ 0.12055883  0.05709751 -0.00104686 -0.02052284 -0.10099893]) 0.3291417956352234: -- kathleen richards email sometimes you're the windshield, sometimes you're the bug!\n",
      "politics ([-0.0189478  -0.06962198 -0.06771603 -0.00329312 -0.06759918]) 0.17470255494117737: -dire straits\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1\n",
    "print(\"Initial CO Class Weights:\") \n",
    "printClasses(init_class_weights[doc_id])\n",
    "# print(\"Initial PLM Class Weights: \", init_plm_class_weights[doc_id])\n",
    "\n",
    "print(\"Updated Class Weights:\")\n",
    "printClasses(updated_class_weights[doc_id])\n",
    "\n",
    "print(\"True Class: \", class_names[gold_labels[doc_id]])\n",
    "tok_sents = sent_dict[str(doc_id)]\n",
    "chosen_class = np.argmax(cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr), axis=1)\n",
    "sent_classes = cosine_similarity(updated_sent_repr[doc_id, :len(tok_sents)], class_repr)\n",
    "\n",
    "for s,c,cw,w in zip(tok_sents, class_names[chosen_class.astype(int)], sent_classes, updated_sent_weights[doc_id, :len(tok_sents)]):\n",
    "    print(f'{c} ({cw}) {w}: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial CO Class Weights:\n",
      "business: 0.30759900965269593 politics: 0.41130068009186277 sports: 0.0035528031148018913 education: 0.17317906541533593 estate: 0.03225024527217161 science: 0.044217051177306024 technology: 0.027901145275826073 Updated Class Weights:\n",
      "business: 0.28279584739357233 politics: 0.4073226824402809 education: 0.27804237697273493 estate: 0.017167776823043823 arts: 0.014671259559690952 True Class:  education\n",
      "education ([0.57640734 0.57135406 0.55826009 0.46610187 0.66778041 0.5121223\n",
      " 0.53071282 0.58463734 0.59064805]) 0.029201084216249156: in the first year of the new russia , a group of students enrolled in a new western style graduate school to learn a long forbidden academic discipline market economics .\n",
      "business ([0.3393767  0.32187175 0.31154182 0.27653444 0.31493925 0.29866308\n",
      " 0.30016655 0.30211372 0.32391569]) 0.005853290864809215: they were heady days .\n",
      "politics ([0.47754115 0.54335834 0.45258943 0.44714381 0.43593186 0.42433767\n",
      " 0.46249914 0.43247215 0.45784458]) 0.024917343148422706: the soviet_union had just collapsed .\n",
      "business ([0.53156225 0.51609223 0.45008386 0.3924122  0.46703648 0.43692886\n",
      " 0.42033282 0.42870363 0.4727588 ]) 0.005856703080307776: economic reforms were beginning , sending prices spinning .\n",
      "politics ([0.56370632 0.56377547 0.51690953 0.45672495 0.49995796 0.54676282\n",
      " 0.53303174 0.50015662 0.5384243 ]) 2.6179395668196945e-05: new social classes of the fantastically rich and painfully poor were beginning to emerge .\n",
      "education ([0.54358739 0.51165643 0.52502008 0.40415463 0.57150818 0.44116275\n",
      " 0.47938653 0.51887763 0.5170646 ]) 0.010570369358888556: the students , 20 year olds from moscow universities , wanted to understand it .\n",
      "business ([0.66253407 0.62370344 0.58533589 0.47206801 0.60849266 0.52893213\n",
      " 0.52840799 0.57017118 0.59671232]) 0.01470065608615173: now , 10 years later , the graduates of the new economics school have grown into some of russia 's most promising young leaders .\n",
      "technology ([0.67217682 0.59943672 0.55852339 0.57816597 0.62851762 0.5760554\n",
      " 0.5515512  0.64437924 0.69624905]) 0.009113361778164636: one became the youngest deputy minister in the government at age 29 . another was hired by the sloan school of management at the massachusetts_institute_of_technology as one of the few women to teach there .\n",
      "business ([0.70522721 0.55447373 0.50218876 0.49307111 0.47113781 0.58465753\n",
      " 0.47556458 0.51095778 0.55262704]) 0.045645761158149674: yet another is chief_executive_officer of a large investment fund in moscow .\n",
      "education ([0.48828763 0.51287209 0.51598922 0.40882471 0.58095084 0.4602786\n",
      " 0.47730535 0.47658261 0.47742058]) 0.02459343367546833: the first graduating_class gathered for its 10th reunion in moscow late last month .\n",
      "politics ([0.64392934 0.69640753 0.52501958 0.4820367  0.53678104 0.51777995\n",
      " 0.50315175 0.57451767 0.57494414]) 0.019867408338064562: the event , held as a conference on the russian economy , was attended by many leading policy_makers , including the russian finance minister and the former no .\n",
      "business ([0.472473   0.446596   0.41295108 0.40101938 0.39891077 0.40973202\n",
      " 0.38917789 0.40364411 0.40267833]) 0.009796620903371937: 2 official at the international_monetary_fund .\n",
      "politics ([0.48089723 0.55960336 0.46842477 0.44646144 0.42717479 0.42388248\n",
      " 0.42186395 0.44126822 0.42632527]) 0.029796885722151105: even president vladimir v . putin sent his congratulations .\n",
      "business ([0.72616093 0.62501096 0.63130633 0.5644068  0.68969994 0.58006801\n",
      " 0.55947223 0.63626598 0.66640286]) 0.013803548016810852: the 34 graduates of the first class , now in jobs in business , education and government , were the first to receive a western style graduate education in economics after the soviet_union fell apart .\n",
      "education ([0.53465555 0.48689354 0.48819677 0.44932052 0.57134069 0.47552417\n",
      " 0.49678574 0.5217847  0.55351436]) 0.006748764607042344: many went on to receive advanced degrees from american or western_european universities .\n",
      "politics ([0.56760892 0.63942558 0.53932963 0.44304583 0.53095265 0.48377012\n",
      " 0.55504129 0.53004074 0.57990092]) 0.02253508812492069: those who returned brought fresh ideas and outlooks to russia , and now are a powerful force for change .\n",
      "business ([0.69016352 0.67959912 0.55860024 0.53190326 0.54878257 0.55651097\n",
      " 0.52823515 0.58744011 0.6051222 ]) 0.003999514063808702: ''their worldview is much wider than ours was , '' oleg v . vyugin , 50 , first deputy chairman of the russian central_bank , said during the reunion .\n",
      "politics ([0.42912345 0.43869675 0.40390152 0.35081897 0.39995158 0.36620312\n",
      " 0.37441256 0.39554364 0.38476057]) 0.003624300677919688: ''they are not afraid .\n",
      "technology ([0.45959706 0.43651244 0.45212767 0.35840013 0.43314363 0.39594247\n",
      " 0.42952535 0.41199811 0.49075649]) 0.011796464422226037: they are capable of working here or anywhere .\n",
      "politics ([0.42745806 0.45351191 0.40620918 0.38154172 0.41940959 0.41162905\n",
      " 0.40690521 0.3672533  0.39474843]) 0.009863570017052268: it 's all the same for them .\n",
      "sports ([0.35915182 0.37719598 0.40553158 0.33527969 0.40235019 0.3453308\n",
      " 0.37190896 0.37086097 0.39915583]) 0.0012044250914703437: that 's new . ''\n",
      "politics ([0.50243564 0.55962391 0.46922225 0.42738737 0.49081248 0.46526272\n",
      " 0.48352482 0.47883407 0.52788646]) 0.012015293460427795: they were a generation on the cusp of change .\n",
      "education ([0.60631029 0.64689145 0.57259411 0.47789938 0.66155176 0.52788898\n",
      " 0.55828424 0.57399403 0.63321   ]) 0.005550160397437791: the one just ahead of them , already in the work force at the end of the soviet_union , produced the young reformers of the 1990 's , who taught themselves economics from textbooks and set russia careering toward capitalism .\n",
      "business ([0.75290565 0.6315434  0.59265818 0.50371127 0.52681243 0.62199412\n",
      " 0.53801605 0.55147093 0.61017831]) 0.04594581317599151: it also begot the business tycoons who profiteered during the free for all that followed .\n",
      "politics ([0.46477488 0.53346563 0.46682699 0.34785755 0.45743101 0.40835752\n",
      " 0.45769613 0.44636375 0.48776775]) 0.017300492602041632: the generation after them barely remembers communism .\n",
      "politics ([0.6677637  0.7085344  0.58450815 0.52961975 0.60734015 0.56943454\n",
      " 0.54835285 0.64006619 0.63768735]) 0.015435135667479682: ''our generation has a mix of old and new , '' said arkady v . dvorkovich , a new economics school graduate who is now a deputy minister on the government 's economic_reform team .\n",
      "science ([0.52433921 0.52049741 0.48606129 0.39536168 0.48516115 0.4428551\n",
      " 0.48369883 0.52983259 0.52863498]) 0.00045339427375629864: ''we still had marx and pioneer camps .\n",
      "education ([0.50948068 0.50895971 0.51551905 0.40164764 0.65020841 0.45393379\n",
      " 0.4813592  0.48839632 0.51488531]) 0.05099124910706583: for students several years younger than us , that did n't exist .\n",
      "business ([0.50208351 0.47630917 0.47304714 0.38791851 0.49762146 0.44956854\n",
      " 0.44965591 0.43295923 0.47348027]) 0.001689259597443363: for those who were older , it is all they knew . ''\n",
      "politics ([0.49212759 0.56652233 0.4453982  0.35719424 0.52210901 0.44731307\n",
      " 0.45137168 0.45890294 0.49379784]) 0.016814173192532398: the graduates are also distinctly less cynical than the preceding generation .\n",
      "business ([0.74368282 0.69742253 0.60329597 0.52521207 0.58453001 0.60596254\n",
      " 0.57521522 0.6065175  0.63570357]) 0.01751341053444121: while tycoons were grabbing oil companies and reformers were dismantling the economy , mr . dvorkovich and many of his fellow students were trying to understand it .\n",
      "politics ([0.59248722 0.64909797 0.56710171 0.52961309 0.61939592 0.54784358\n",
      " 0.52431039 0.61210993 0.58047584]) 0.011244723153189173: after receiving a master 's degree from duke_university , mr . dvorkovich returned to take a job in government .\n",
      "politics ([0.57028652 0.6060286  0.50855069 0.4455941  0.52493785 0.48870865\n",
      " 0.45887945 0.53293598 0.55874115]) 0.013531381278153055: at 27 he became one of the architects of mr . putin 's economic program .\n",
      "business ([0.69606218 0.65392194 0.55363922 0.49333715 0.52844965 0.54591512\n",
      " 0.47911012 0.523779   0.56771215]) 0.01595362650322674: his current position as deputy minister pays less than he could expect in private business , but he lives frugally , helped by savings from previous consulting work .\n",
      "politics ([0.55344818 0.62505965 0.54183741 0.43340548 0.53485415 0.48227615\n",
      " 0.53269944 0.55627885 0.58738378]) 0.014263484907498687: ''we can think in soviet ways or in new ways , '' he said at his office recently .\n",
      "politics ([0.52517471 0.573714   0.47859996 0.44420981 0.50848831 0.49630079\n",
      " 0.48507785 0.45132106 0.50541561]) 0.018376199879579246: ''it leads to easier compromise , but sometimes it creates conflict inside yourself .\n",
      "politics ([0.48874021 0.54245889 0.43846494 0.43656098 0.48691981 0.45495241\n",
      " 0.48484816 0.45629759 0.46898867]) 0.020337038041855632: we see that it is not right to smash everything from the past .\n",
      "sports ([0.40086204 0.40832887 0.42135351 0.36190433 0.41515045 0.37949919\n",
      " 0.36964137 0.37718141 0.38321147]) 0.0023483780233315476: some of it was good . ''\n",
      "politics ([0.55124705 0.66629259 0.47525538 0.46208728 0.52243558 0.4710301\n",
      " 0.50426675 0.54762861 0.51976548]) 0.04355440711160147: other graduates have also influenced public_policy .\n",
      "science ([0.65879952 0.68379835 0.62571149 0.55755759 0.64395844 0.57128386\n",
      " 0.58302876 0.7372335  0.67803212]) 0.020229696384230667: the economic expert group , a research organization run by former students , provided the first reliable economic statistics to the russian government , an important service in a country where the state of the economy had long been treated as a state secret .\n",
      "education ([0.58687856 0.57450192 0.55892762 0.50840595 0.6684803  0.52078103\n",
      " 0.5330429  0.59984251 0.58467615]) 0.02598517698027515: the new economics school brought leading economics professors from american and other western universities to teach the equivalent of the first two years of a western style doctorate in economics , with a certificate at the end that is comparable to a master 's degree .\n",
      "business ([0.70236334 0.65997546 0.63708595 0.54211491 0.58184799 0.62755876\n",
      " 0.60036071 0.65025663 0.6489955 ]) 0.016047375521390395: it was started by an israeli economics professor with a grant from the american philanthropist george_soros and is based in a drab moscow high rise that once housed the soviet_union 's top mathematicians .\n",
      "science ([0.66158841 0.64377958 0.57963762 0.53794951 0.58044183 0.56913867\n",
      " 0.54637902 0.69356376 0.63175459]) 0.012105360278375886: ''the change was already in the air , '' said yekaterina zhuravskaya , 30 , a graduate who is now a director at the center for economic and financial research here .\n",
      "politics ([0.56956268 0.64100528 0.5400995  0.4504854  0.57787563 0.50672477\n",
      " 0.52334624 0.564926   0.58189503]) 0.022378200962327514: russian colleges , she said , ''taught the same old stuff political_economy , socialism , weird things like that .\n",
      "technology ([0.42793758 0.44168477 0.4476231  0.34880482 0.45750709 0.36860061\n",
      " 0.42493362 0.39658973 0.46998195]) 0.004722784976138667: there was a lack of something new . ''\n",
      "politics ([0.40532879 0.44878648 0.40541824 0.3406889  0.42295364 0.40800579\n",
      " 0.40373116 0.40296197 0.42876403]) 0.007580181781802741: lifestyles also differ from a decade ago .\n",
      "business ([0.60380198 0.50754426 0.52134529 0.4501943  0.55147382 0.50176369\n",
      " 0.48269914 0.48235721 0.55202537]) 0.019601801351819232: graduates travel abroad freely , speak foreign languages and change jobs easily .\n",
      "estate ([0.58431902 0.54445677 0.52901741 0.51632378 0.54832522 0.6695055\n",
      " 0.53849253 0.50534456 0.53598902]) 0.03225024527217161: ms . zhuravskaya , who shares a two room apartment with her husband and baby , rarely cooks , buys groceries over the internet and drives to work .\n",
      "business ([0.62898635 0.58826104 0.56001468 0.49637681 0.58960927 0.56986363\n",
      " 0.55220678 0.58726701 0.58799586]) 0.01490753649907514: she went on to receive her doctorate in economics from harvard and had her pick of jobs , but chose to return to russia , in part , she said , because she saw more opportunities here .\n",
      "business ([0.6413863  0.60958678 0.51539616 0.44991202 0.50145979 0.50494962\n",
      " 0.49589551 0.54637831 0.56882808]) 0.012038791642590453: since returning , she too has had a hand in shaping the russian economy .\n",
      "business ([0.81436834 0.63510845 0.5836645  0.53251003 0.59188651 0.60829885\n",
      " 0.55108587 0.59474601 0.64466944]) 0.06424530065330795: a world_bank financed study of small business that she led has shown moscow officials the shortcoming of their policies for reducing red_tape for small businesses .\n",
      "education ([0.45102156 0.39953947 0.41225115 0.3316078  0.49082278 0.38150473\n",
      " 0.40004505 0.41628828 0.42409582]) 0.015068108382143716: other graduates , however , stayed abroad .\n",
      "science ([0.62579766 0.60131293 0.58366411 0.52547054 0.63689309 0.53808534\n",
      " 0.5403463  0.66708084 0.61844178]) 0.01142860024094317: anna pavlova , now 29 , joined the sloan school 's faculty in 2000 . she said she had not returned to russia to work because her field finance is not an academic discipline here .\n",
      "education ([0.5169157  0.54747498 0.50353548 0.45149842 0.55928403 0.48454919\n",
      " 0.48378684 0.45877797 0.47759953]) 0.004470718690765026: back at the reunion , young people packed an auditorium .\n",
      "politics ([0.62408589 0.72091789 0.53398756 0.49800863 0.51765564 0.52313358\n",
      " 0.50247928 0.57200591 0.59967087]) 0.03665905648715238: under the lights , top policy_makers were debating recipes for economic_growth .\n",
      "politics ([0.40090316 0.42209728 0.36940544 0.32330491 0.40400564 0.33987118\n",
      " 0.38763529 0.36737185 0.36128312]) 0.006849204835430997: among them was mr . dvorkovich .\n",
      "politics ([0.65416294 0.75888628 0.59763556 0.51762446 0.61264961 0.57293272\n",
      " 0.545315   0.60144057 0.62582086]) 0.03964658838125666: ''sooner or later probably sooner they will come to take over the reins of power , '' andrei n . illarionov , 41 , one of the other panelists and an economic adviser to mr . putin , said of the young graduates .\n",
      "technology ([0.51447659 0.53375704 0.47851355 0.41711169 0.5227389  0.46926112\n",
      " 0.46572742 0.49028702 0.53974919]) 0.002268534099296733: ''they will do a better job than my generation .\n",
      "politics ([0.38811382 0.41007495 0.37791166 0.35486831 0.38824873 0.38839033\n",
      " 0.39770162 0.37009018 0.37982005]) 0.004684342925334406: i certainly hope so . ''\n"
     ]
    }
   ],
   "source": [
    "# sentence centrality\n",
    "doc_id = 46\n",
    "print(\"Initial CO Class Weights:\") \n",
    "printClasses(init_class_weights[doc_id])\n",
    "# print(\"Initial PLM Class Weights: \", init_plm_class_weights[doc_id])\n",
    "\n",
    "print(\"Updated Class Weights:\")\n",
    "printClasses(curr_class_weights[doc_id])\n",
    "\n",
    "print(\"True Class: \", class_names[gold_labels[doc_id]])\n",
    "tok_sents = sent_dict[str(doc_id)]\n",
    "r = padded_sent_repr\n",
    "chosen_class = np.argmax(cosine_similarity(r[doc_id, :len(tok_sents)], class_repr), axis=1)\n",
    "sent_classes = cosine_similarity(r[doc_id, :len(tok_sents)], class_repr)\n",
    "\n",
    "for s,c,cw,w in zip(tok_sents, class_names[chosen_class.astype(int)], sent_classes, init_sent_weights[doc_id, :len(tok_sents)]):\n",
    "    print(f'{c} ({cw}) {w}: {s}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA on Document Embeddings & Fit GMM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained document variance: 0.6766643806335045\n"
     ]
    }
   ],
   "source": [
    "_pca = PCA(n_components=16, random_state=args.random_state)\n",
    "pca_doc_repr = _pca.fit_transform(final_doc_emb)\n",
    "# pca_sent_repr = _pca.fit_transform(updated_sent_repr.reshape((-1, 768)))\n",
    "# pca_sent_repr = pca_sent_repr.reshape((-1, args.max_sent, 64))\n",
    "# pca_doc_repr = _pca.fit_transform(np.sum(padded_sent_repr, axis=1)/doc_lengths.reshape((-1, 1)))\n",
    "# pca_doc_repr = _pca.fit_transform(doc_repr)\n",
    "# pca_class_repr = [_pca.transform(class_set[i]) for i in np.arange(len(class_set))]\n",
    "pca_class_repr = [_pca.transform(init_class_set[i]) for i in np.arange(len(init_class_set))]\n",
    "# pca_class_repr = _pca.transform(plm_class_repr)\n",
    "print(f\"Explained document variance: {sum(_pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.5294993153539322\n",
      "F1 macro: 0.5217685750130246\n"
     ]
    }
   ],
   "source": [
    "doc_class_assignment, doc_class_cos = docToClassSet(pca_doc_repr, pca_class_repr, None)\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)\n",
    "# doc_class_assignment, doc_class_cos = docToClassSet(final_doc_emb, class_repr.reshape((26, 1, -1)), None)\n",
    "# NEW: Use regularized softmax to transform cosine-similarities into probabilities and rank confident docs based on top-two ratio\n",
    "reg_temp = 0.2\n",
    "doc_class_dist = np.exp(doc_class_cos/reg_temp)/np.sum(np.exp(doc_class_cos/reg_temp), axis=1).reshape(-1,1)\n",
    "\n",
    "# doc_assignment_probs = doc_class_dist[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "# doc_toptwo = np.partition(doc_class_dist, -2)[:, -2:] # N x 2\n",
    "# doc_toptwo = np.partition(doc_class_cos, -2)[:, -2:] # N x 2\n",
    "# doc_toptwo = doc_toptwo[:, 1] - doc_toptwo[:, 0] # N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science :  Re Migraines and Estrogen In article (Peggy Wageman) writes I read that hormonal fluctuations can contribute to migraines, could taking supplemental estrogen (ERT) cause migraines? Any information I'm not sure it is the fluctuation so much as the estrogen level. Taking Premarin can certainly cause migraines in some women. -- ---------------------------------------------------------------------------- Gordon Banks N3JXP \"Skepticism is the chastity of the intellect, and it is shameful to surrender it too soon.\" ----------------------------------------------------------------------------\n",
      "computer :  0.00477684940169282\n",
      "sports :  0.06798844065948896\n",
      "science :  0.7312896166292748\n",
      "politics :  0.0748134569428074\n",
      "religion :  0.12113163636673609\n"
     ]
    }
   ],
   "source": [
    "doc_id = 5\n",
    "print(class_names[gold_labels[doc_id]],\": \", cleaned_text[doc_id])\n",
    "for idx, c in enumerate(class_names):\n",
    "    print(c, \": \", doc_class_dist[doc_id][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.7898270941749203\n",
      "F1 macro: 0.7651374709330063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[4713, 47, 73, 24, 34],\n",
       "  [71, 3703, 55, 105, 45],\n",
       "  [1309, 136, 1771, 587, 149],\n",
       "  [24, 81, 34, 1678, 808],\n",
       "  [12, 17, 18, 127, 2250]],\n",
       " 'f1_micro': 0.7898270941749203,\n",
       " 'f1_macro': 0.7651374709330063}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-oriented final doc\n",
    "# cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "# doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "# doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "# doc_class_probs = updated_class_weights[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "doc_class_assignment = docToClassSet(pca_doc_repr, pca_class_repr, None)\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.8893947368421051\n",
      "F1 macro: 0.8893947349271942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion': [[16901, 2099], [2104, 16896]],\n",
       " 'f1_micro': 0.8893947368421051,\n",
       " 'f1_macro': 0.8893947349271942}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-oriented average\n",
    "cosine_similarities = cosine_similarity(pca_doc_repr, pca_class_repr)\n",
    "doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "doc_class_probs = cosine_similarities[np.arange(pca_doc_repr.shape[0]), doc_class_assignment]\n",
    "\n",
    "print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "evaluate_predictions(gold_labels, doc_class_assignment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pseudo Training Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_dir(text, labels, prob, data_path, new_data_path):\n",
    "    assert len(text) == len(labels)\n",
    "    print(\"Saving files in:\", new_data_path)\n",
    "    \n",
    "    with open(os.path.join(new_data_path, \"dataset.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(text):\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"labels.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(labels):\n",
    "            f.write(str(line))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(os.path.join(new_data_path, \"probs.txt\"), \"w\") as f:\n",
    "        for i, line in enumerate(prob):\n",
    "            # f.write(str(line))\n",
    "            f.write(\",\".join(map(str, line)))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    copyfile(os.path.join(data_path, \"classes.txt\"),\n",
    "             os.path.join(new_data_path, \"classes.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(documents_to_class, ranks, class_dist, num_classes, cleaned_text, gold_labels, data_path, new_data_path, thresh=0.5):\n",
    "    pseudo_document_class_with_confidence = [[] for _ in range(num_classes)]\n",
    "    for i in range(documents_to_class.shape[0]):\n",
    "        pseudo_document_class_with_confidence[documents_to_class[i]].append((ranks[i], i))\n",
    "\n",
    "    selected = []\n",
    "    confident_documents = [[] for _ in range(num_classes)]\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        pseudo_document_class_with_confidence[i] = sorted(pseudo_document_class_with_confidence[i], key=lambda x: x[0], reverse=True)\n",
    "        num_docs_to_take = int(len(pseudo_document_class_with_confidence[i]) * thresh)\n",
    "        confident_documents[i] = pseudo_document_class_with_confidence[i][:num_docs_to_take]\n",
    "        selected.extend([x[1] for x in confident_documents[i]])\n",
    "    \n",
    "    selected = sorted(selected)\n",
    "    text = [cleaned_text[i] for i in selected]\n",
    "    classes = [documents_to_class[i] for i in selected]\n",
    "    probs = [class_dist[i] for i in selected]\n",
    "    ###\n",
    "    gold_classes = [gold_labels[i] for i in selected]\n",
    "    evaluate_predictions(gold_classes, classes)\n",
    "    ###\n",
    "    # write_to_dir(text, classes, probs, data_path, new_data_path)\n",
    "    return confident_documents\n",
    "\n",
    "def updateClassSet(confident_docs, doc_emb, class_set):\n",
    "    for i in np.arange(len(class_set)):\n",
    "        doc_ind = [d[1] for d in confident_docs[i]]\n",
    "        class_set[i] = np.concatenate((np.expand_dims(class_set[i][0], axis=0), doc_emb[doc_ind, :]), axis=0)\n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro: 0.7200714711137582\n",
      "F1 macro: 0.7085271151734461\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.2\n",
    "reg_temp = 0.2\n",
    "doc_class_dist = np.exp(doc_class_cos/reg_temp)/np.sum(np.exp(doc_class_cos/reg_temp), axis=1).reshape(-1,1)\n",
    "doc_rank = np.max(doc_class_cos, axis=1)\n",
    "\n",
    "finalconf = generateDataset(doc_class_assignment, doc_rank, doc_class_dist, num_classes, cleaned_text, gold_labels, data_path, new_data_path, thresh)\n",
    "updateClassSet(finalconf, final_doc_emb, class_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business: 708\n",
      "politics: 673\n",
      "sports: 231\n",
      "health: 205\n",
      "education: 162\n",
      "estate: 190\n",
      "arts: 91\n",
      "science: 23\n",
      "technology: 111\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(len(finalconf)):\n",
    "    print(f'{class_names[i]}: {len(finalconf[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['computer', 'sports', 'science', 'politics', 'religion'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 computer :  0.9274725274725275\n",
      "1 sports :  1.0\n",
      "2 science :  0.9886363636363636\n",
      "3 politics :  0.8904109589041096\n",
      "4 religion :  0.9903381642512077\n"
     ]
    }
   ],
   "source": [
    "# class_id = 2\n",
    "for class_id in np.arange(len(class_names)):\n",
    "    # results = [doc_class_assignment[i[1]] == gold_labels[i[1]] for i in finalconf[class_id][:50]]\n",
    "    # print(np.sum(results)/len(results))\n",
    "    all_results = [doc_class_assignment[i[1]] == gold_labels[i[1]] for i in finalconf[class_id]]\n",
    "    print(class_id, class_names[class_id], \": \", np.sum(all_results)/len(all_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5058,\n",
       " 'Re Monophysites and Mike Walker Nabil Ayoub writes As a final note, the Oriental Orthodox and Eastren Orthodox did sign a common statement of Christology, in which the heresey of Monophysitism was condemned. So the Coptic Orthodox Church does not believe in Monophysitism. Sorry! What does the Coptic Church believe about the will and energy of Christ? Were there one or were there two (i.e. Human and Divine) wills and energies in Him. Also, what is the objection ot the Copts with the Pope of Rome (i.e. why is there a Coptic Catholic Church)? Do you reject the supreme jurisdiction of the 263rd sucessor of St. Peter (who blessed St. John Mark, Bishop of Alexandria was translator for) and his predecessors? Or his infallibility? Or what other things perhaps? Andy Byler',\n",
       " 'religion',\n",
       " array([0.00452341, 0.01535639, 0.01955483, 0.02291949, 0.93764589]),\n",
       " 'religion')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = finalconf[4][0][1]\n",
    "doc_id, cleaned_text[doc_id], class_names[doc_class_assignment[doc_id]], doc_class_dist[doc_id], class_names[gold_labels[doc_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"medical journals are the prime source of information about scientific advances that can change how doctors treat patients in offices and in hospitals . and to ensure the quality of what journals publish , their editors , beginning 200 years ago , have increasingly called on scientific peers to review new findings from research in test tubes and on animals and humans . the system , known as peer_review , is now considered a linchpin of science . editors of the journals and many scientists consider the system 's expense and time consumption worthwhile in the belief that it weeds out shoddy work and methodological errors and blunts possible biases by scientific investigators . another main aim is to prevent authors from making claims that cannot be supported by the evidence they report . yet for all its acclaim , the system has long been controversial . despite its system of checks and balances , a number of errors , plagiarism and even outright fraud have slipped through it . at the same time , the system has created a kind of good housekeeping seal of approval that gets stamped on research published in journals . although most research is solid , and in some cases groundbreaking , problems have persisted . a particular concern is that because editors and reviewers examine only what authors summarize , not raw data , the system can provide false reassurances that what is published is scientifically sound . after a series of problems , about 20 years ago , journal editors came under pressure to better document claims for the system 's merits . to do that , a number of editors began their own primary research into the way the peer_review system worked , what was wrong and how it could be fixed . a leader has been the journal of the american_medical_association , which has held four meetings on research on peer_review since 1989 under the direction of dr . drummond rennie , a deputy editor . last week , the journal published 34 articles from the latest meeting . and the news was grim . researchers reported considerable evidence that many statistical and methodological errors were common in published papers and that authors often failed to discuss the limitations of their findings . even the press_releases that journals issue to steer journalists to report peer reviewed papers often exaggerate the perceived importance of findings and fail to highlight important caveats and conflicts of interest . ''once again , '' dr . rennie wrote in an editorial summarizing the findings , ''we publish studies that fail to show any dramatic effect , let alone improvement , brought about by editorial peer_review . '' under the system , authors submit manuscripts to journals whose editors send the most promising ones to other experts ( peers ) in academic medicine to solicit their unpaid advice . the peers check for obvious errors , internal inconsistencies , logic , statistical legitimacy , reasonableness of conclusions and many other factors , and make suggestions that editors use in deciding whether to ask for revisions , publish the paper or return it marked ' 'rejected . '' there is general agreement that an overwhelming majority of ''weak'' papers will survive initial rejections to find acceptance somewhere among the thousands of medical and scientific journals that each year publish an estimated two million new research articles , mostly paid for by the public through government grants . despite improvements in peer_review , ''there still is a massive amount of rubbish'' in the journals , dr . rennie said . in recent years , editors have used the importance of peer_review to justify imposing punitive restrictions on authors who disclose information to the press before the paper 's publication in their journals . by linking peer_review and publication date , critics say , editors have increased the news value of their journals , a step that has slowed the free flow of information and helped some journals raise subscriptions , advertisement rates and profits . while many editors and others have defended the system , they acknowledge that it is unlikely to detect fraud and is prone to abuse . one reason is that the secrecy involved in the system can be unfair to authors . while the names of authors are generally known to reviewers , the reviewers' names are not disclosed to the authors . because the anonymous peers chosen to review manuscripts are often the authors' scientific competitors , jealousies and competitive_advantage can become factors in the reviews . occasionally , reviewers have been caught publishing information they lifted from other researchers' manuscripts . further , little is known about the quality of the reviewers or what training they need to do a good job . ''the available evidence , '' wrote fiona godlee of biomed central in london , ''gives no indication that anonymous peer_review achieves better scientific results than open review . '' apparently , few journals have adopted the open system . ms . godlee said she looked forward to the day when signed reviews were posted on the internet along with published articles . the peer_review system also tends to set a very high barrier for authors to publish truly novel findings . in 1796 , a peer reviewed journal in england rejected dr . edward jenner 's report of his development of the world 's first vaccine , against smallpox . the vaccine was used to eradicate the viral disease nearly two centuries later , and it may be needed again if bioterrorists release smallpox virus in an attack . in recent decades , at least two nobel_prizes were awarded to scientists who received rejection slips from one journal before another published their papers . one paper concerned what turned out to be the hepatitis b virus . the other concerned a radio immunoassay technique that can detect trace amounts of substances in the body and that is now used every day throughout the world . another recent problem , critics say , is that many editors have not moved quickly enough to use newer methods to judge the merits of manuscripts . one example is the growing importance of statistics to measure the safety and effectiveness of new therapies and to compare them with older ones . yet research on peer_review has found that many studies are conducted without the benefit of adequate consultation with statisticians , sometimes because none were available . reasons for errors also include the practice of consulting statisticians after the research project has been completed , not at the most critical time , when the study was being designed . ''expert analysis cannot salvage poorly designed research , '' wrote dr . douglas g . altman of the center for statistics in medicine in oxford , england . once statistical errors are published , it is hard to stop them from spreading and being cited uncritically by others . dr . richard horton , editor of the lancet , found in his own study that reviewers often did not detect important limitations to research findings that authors left out of their papers . the omission , dr . horton said , must be judged a failure of peer_review . yet dr . rennie remained optimistic . earlier research has led to some improvements . for example , in an interview dr . rennie said that findings from research in peer_review had led some medical journals to adopt more standardized systems for reporting findings from the clinical_trials that were used to determine the safety and effectiveness of new drugs and other therapies . also , because reviewers are selected for expertise the editors do not have , reviewers often rescue a paper from rejection . for example , dr . rennie cited a scientist who found scientific merit in an author 's manuscript that dr . rennie had sent him . the reviewer ''completely rewrote'' the manuscript that he ''would have rejected otherwise , '' dr . rennie said . no one knows how often such ' 'rescues'' occur , dr . rennie said , in part because the needed studies have not been done . such studies would involve funds that have been hard to obtain as well as cooperation of reviewers , editors and authors of papers that were accepted and rejected , and many of them might not participate because of their set views . in 1986 , dr . stephen lock , then editor of the british_medical_journal , wrote , ''editors , the arbiters of rigor , quality and innovativeness in publishing scientific work , do not apply to their own work the standards they apply to judging the work of others . '' defenders of the system still face dr . lock 's challenge . the doctor's world\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial CO Class Weights:  [0.0036531  0.         0.         0.05012046 0.         0.\n",
      " 0.         0.94373815 0.00248829]\n",
      "Updated Class Weights:  [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99999996 0.        ]\n",
      "True Class:  3\n",
      "science ([0.11058517 0.1084116  0.10210798 0.11702134 0.10733373 0.09862915\n",
      " 0.10505607 0.12718393 0.12367104]) 0.009585914145700859: a new study in which mouse brains were examined says prolonged stress and drugs like those given to troops in the persian_gulf_war can have long lasting effects on the brain .\n",
      "science ([0.11192069 0.11428407 0.10495972 0.11785007 0.10390442 0.10154774\n",
      " 0.10696098 0.12862321 0.1099491 ]) 0.029937306097804286: the results , the researchers say , could help explain two controversial afflictions of some service members post_traumatic_stress syndrome and gulf_war_syndrome .\n",
      "science ([0.1090294  0.10522888 0.10683364 0.11248761 0.10348834 0.09249359\n",
      " 0.10123969 0.15034217 0.11885668]) 0.08042533166769485: the researchers , led by dr . hermona soreq of hebrew university in jerusalem , forced mice to swim , which is very stressful to them .\n",
      "science ([0.11005829 0.10750765 0.10438601 0.10320033 0.10591501 0.09685948\n",
      " 0.10704108 0.14200305 0.12302911]) 0.049086931963713276: then the researchers studied slices of the animals' brains , looking for effects on acetylcholine , a chemical that is used to transmit nerve impulses .\n",
      "science ([0.11192168 0.11652342 0.10499084 0.10127875 0.10205677 0.09566569\n",
      " 0.10590295 0.1446957  0.1169642 ]) 0.07281715210635481: the researchers' hypothesis is that acetylcholine promotes the brain 's activities .\n",
      "business ([0.11651814 0.11016249 0.10585616 0.10931695 0.10846668 0.11169753\n",
      " 0.10771375 0.11498726 0.11528104]) 0.003653103249179602: stress , which is deleterious , can reduce acetylcholine levels in two ways after causing a brief increase in the amount of acetylcholine , stress slows the chemical 's production and speeds the rate that it is degraded .\n",
      "science ([0.11046459 0.10578041 0.10426895 0.10396222 0.10115064 0.09553901\n",
      " 0.10437826 0.15667644 0.11777948]) 0.09766518513262469: in their experiments , published today in nature magazine , the researchers found that stress reduced the amount of the enzyme that makes acetylcholine .\n",
      "science ([0.11000283 0.10711465 0.10669207 0.11040484 0.11232532 0.10040817\n",
      " 0.10777853 0.13254537 0.11272822]) 0.05542447715503167: in addition , in tests over 80 hours , stress increased the amount and the activity of the enzyme that degrades acetylcholine .\n",
      "science ([0.11007718 0.10840262 0.10123946 0.10943527 0.10596583 0.09530303\n",
      " 0.1026024  0.14448868 0.12248553]) 0.056541244668301516: from those data , the researchers suggested that stress in humans might cause memory disruptions and other mental problems through a similar biochemical effect .\n",
      "science ([0.10917761 0.10696169 0.10156037 0.10933681 0.10858924 0.09708438\n",
      " 0.10176383 0.14419268 0.1213334 ]) 0.05907384214124829: the researchers also examined the effects of a drug on slices of the animals' brains .\n",
      "technology ([0.10671428 0.11000657 0.10177641 0.12677931 0.10855755 0.10078602\n",
      " 0.10300985 0.11466558 0.12770442]) 0.002488290404591923: the drug , pyridostigmine , is similar to one given to troops in the gulf_war to protect them from nerve_gas .\n",
      "science ([0.11354359 0.10964168 0.10397258 0.10598393 0.10969169 0.09779999\n",
      " 0.10738319 0.13576404 0.11621931]) 0.053197903367926444: the researchers reported that over periods of a few minutes , the effects of the pyridostigmine were consistent with their stress model .\n",
      "science ([0.10879008 0.1098282  0.10198669 0.12488287 0.10686001 0.10276943\n",
      " 0.10515528 0.12896208 0.11076537]) 0.011000402159192159: from that experiment , they proposed that pyridostigmine might have caused long term psychiatric symptoms like those of stress , and for the same reason .\n",
      "science ([0.10696594 0.11782734 0.10462535 0.10876461 0.11265265 0.09674572\n",
      " 0.10150741 0.14056693 0.11034405]) 0.060393220903363055: neurobiolgists were cautious in drawing conclusions from the study .\n",
      "science ([0.10091523 0.09851621 0.09555672 0.14912597 0.09392755 0.09579166\n",
      " 0.09863947 0.15331646 0.11421073]) 0.009484470419661883: ''it is interesting to report chronic changes that are the result of acute stress , '' said dr . ronald mckay , chief of the molecular biology laboratory at the national institute of neurological disorders and stroke .\n",
      "science ([0.10569708 0.12034667 0.10345994 0.11549153 0.1120927  0.09571776\n",
      " 0.10136953 0.13321901 0.11260579]) 0.034777933135641696: but , dr . mckay said , ''the difficulty is in relating these highly specific observations to a more generally socially important conclusion . ''\n",
      "health ([0.10170015 0.1020095  0.10017509 0.16067068 0.09606093 0.0952162\n",
      " 0.09954446 0.13878271 0.10584028]) 0.050120459204300145: dr . solomon snyder , a neurobiologist at the johns hopkins university school of medicine , was highly skeptical .\n",
      "science ([0.10920775 0.11599806 0.1041496  0.11298209 0.11119916 0.0963081\n",
      " 0.09986398 0.13999679 0.11029447]) 0.06435727795254757: the authors of the study , dr . snyder said , make ''a giant leap to their conclusions . ''\n",
      "science ([0.10789967 0.11121752 0.10366565 0.11474822 0.1051887  0.09845165\n",
      " 0.10115788 0.14739443 0.11027627]) 0.08568776969289532: the paper was accompanied by an editorial by dr . robert sapolsky , a professor of neuroscience at stanford_university .\n",
      "science ([0.10893429 0.11259823 0.10041614 0.10434194 0.10138968 0.09132981\n",
      " 0.10363959 0.152195   0.12515531]) 0.06694499682377661: dr . sapolsky said the scientists had ''pulled out a plausible pathway'' that might explain the long term effects of stress and , possibly , of chemicals that block the brain 's production of acetylcholine .\n",
      "science ([0.10717814 0.11100372 0.10410672 0.11110021 0.10980357 0.09505476\n",
      " 0.10180131 0.13895019 0.12100136]) 0.04733678760844946: but dr . sapolsky said there were two caveats the studies used rodents , not people , and they involved not whole brains but rather ''a tissue slice and 80 hours in a dish . ''\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial CO Class Weights: \", init_class_weights[doc_id])\n",
    "\n",
    "print(\"Updated Class Weights: \", updated_class_weights[doc_id])\n",
    "print(\"True Class: \", gold_labels[doc_id])\n",
    "tok_sents = sent_dict[str(doc_id)]\n",
    "\n",
    "sent_class_cos = cosine_similarity(padded_sent_repr[doc_id, :len(tok_sents)], class_repr)\n",
    "reg_temp = 0.5\n",
    "sent_class_dist = np.exp(sent_class_cos/reg_temp)/np.sum(np.exp(sent_class_cos/reg_temp), axis=1).reshape(-1,1)\n",
    "\n",
    "chosen_class = np.argmax(sent_class_cos, axis=1)\n",
    "# sent_classes = cosine_similarity(padded_sent_repr[doc_id, :len(tok_sents)], class_repr)\n",
    "\n",
    "for c,cw,w,s in zip(class_names[chosen_class.astype(int)], sent_class_dist, updated_sent_weights[doc_id, :len(tok_sents)], tok_sents):\n",
    "    print(f'{c} ({cw}) {w}: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7317021510492036, 9181)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalconf[4][2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_gmm(args, document_representations, doc_class_representations, gold_labels):\n",
    "    num_classes = len(doc_class_representations)\n",
    "    cosine_similarities = cosine_similarity(document_representations, doc_class_representations)\n",
    "    doc_class_assignment = np.argmax(cosine_similarities, axis=1)\n",
    "\n",
    "    print(\"Evaluate Document Cosine Similarity Predictions: \")\n",
    "    evaluate_predictions(gold_labels, doc_class_assignment)\n",
    "\n",
    "    # initialize gmm based on these selected documents\n",
    "    document_class_assignment_matrix = np.zeros((document_representations.shape[0], num_classes))\n",
    "    for i in np.arange(len(document_representations)): # iterate through docs and sents\n",
    "        document_class_assignment_matrix[i][doc_class_assignment[i]] = 1.0\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_classes, covariance_type='tied',\n",
    "                          random_state=args.random_state,\n",
    "                          n_init=999, warm_start=True)\n",
    "\n",
    "    gmm._initialize(document_representations, document_class_assignment_matrix)\n",
    "    gmm.lower_bound_ = -np.infty\n",
    "\n",
    "    gmm.converged_ = True #HACK FOR NOT RANDOMLY INITIALIZING PARAMS DURING FIT\n",
    "    gmm.fit(document_representations)\n",
    "\n",
    "    documents_to_class = gmm.predict(document_representations)\n",
    "    confidence = gmm.predict_proba(document_representations)\n",
    "\n",
    "    print(\"Evaluate Document GMM Predictions: \")\n",
    "    evaluate_predictions(gold_labels, documents_to_class)\n",
    "\n",
    "    return documents_to_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_class_repr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Document Cosine Similarity Predictions: \n",
      "F1 micro: 0.7002218958027315\n",
      "F1 macro: 0.5808469084409915\n",
      "Evaluate Document GMM Predictions: \n",
      "F1 micro: 0.7940431915492078\n",
      "F1 macro: 0.6569828627562839\n"
     ]
    }
   ],
   "source": [
    "# 128\n",
    "doc_preds, doc_prob = doc_gmm(args, pca_doc_repr, np.array(pca_class_repr).squeeze(1), gold_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bc78f6dd8c9fb4bf4049d09abbebcbc9ae8bd98d8b55b5fea020bfdbf1269a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
